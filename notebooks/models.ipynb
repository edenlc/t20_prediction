{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>innings</th>\n",
       "      <th>total_batter_runs_conceded_mean</th>\n",
       "      <th>total_runs_from_relevant_extras_mean</th>\n",
       "      <th>total_total_runs_conceded_mean</th>\n",
       "      <th>total_taken_from_relevant_wickets_mean</th>\n",
       "      <th>powerplay_batter_runs_conceded_mean</th>\n",
       "      <th>powerplay_runs_from_relevant_extras_mean</th>\n",
       "      <th>powerplay_total_runs_conceded_mean</th>\n",
       "      <th>powerplay_taken_from_relevant_wickets_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>powerplay_runs_batter_mean</th>\n",
       "      <th>powerplay_high_scoring_hit_mean</th>\n",
       "      <th>powerplay_total_mean</th>\n",
       "      <th>powerplay_is_wicket_mean</th>\n",
       "      <th>non_powerplay_runs_batter_mean</th>\n",
       "      <th>non_powerplay_high_scoring_hit_mean</th>\n",
       "      <th>non_powerplay_total_mean</th>\n",
       "      <th>non_powerplay_is_wicket_mean</th>\n",
       "      <th>final_runs</th>\n",
       "      <th>final_wickets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0021ca69-72b5-4080-9e2e-f7cd9e558b47</td>\n",
       "      <td>1</td>\n",
       "      <td>1.060670</td>\n",
       "      <td>-0.513670</td>\n",
       "      <td>1.011385</td>\n",
       "      <td>-0.551914</td>\n",
       "      <td>0.691736</td>\n",
       "      <td>-0.427798</td>\n",
       "      <td>0.586786</td>\n",
       "      <td>-0.163023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.906615</td>\n",
       "      <td>1.147216</td>\n",
       "      <td>0.869648</td>\n",
       "      <td>-0.755857</td>\n",
       "      <td>0.516191</td>\n",
       "      <td>0.368048</td>\n",
       "      <td>0.520429</td>\n",
       "      <td>0.395600</td>\n",
       "      <td>170</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0021ca69-72b5-4080-9e2e-f7cd9e558b47</td>\n",
       "      <td>2</td>\n",
       "      <td>0.861048</td>\n",
       "      <td>0.147495</td>\n",
       "      <td>0.893025</td>\n",
       "      <td>0.872679</td>\n",
       "      <td>0.559383</td>\n",
       "      <td>-0.006142</td>\n",
       "      <td>0.576349</td>\n",
       "      <td>1.455650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711668</td>\n",
       "      <td>0.555493</td>\n",
       "      <td>0.538625</td>\n",
       "      <td>-0.559719</td>\n",
       "      <td>0.789972</td>\n",
       "      <td>0.555270</td>\n",
       "      <td>0.796122</td>\n",
       "      <td>-0.310116</td>\n",
       "      <td>147</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>002795ac-3340-4ccf-9763-865ab0fb8268</td>\n",
       "      <td>1</td>\n",
       "      <td>0.197794</td>\n",
       "      <td>2.108226</td>\n",
       "      <td>0.479992</td>\n",
       "      <td>0.819249</td>\n",
       "      <td>-0.584629</td>\n",
       "      <td>1.416903</td>\n",
       "      <td>-0.411425</td>\n",
       "      <td>1.396177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255541</td>\n",
       "      <td>0.150034</td>\n",
       "      <td>0.399280</td>\n",
       "      <td>0.147236</td>\n",
       "      <td>0.737713</td>\n",
       "      <td>0.817304</td>\n",
       "      <td>1.010981</td>\n",
       "      <td>0.106142</td>\n",
       "      <td>136</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>002795ac-3340-4ccf-9763-865ab0fb8268</td>\n",
       "      <td>2</td>\n",
       "      <td>0.275919</td>\n",
       "      <td>0.611244</td>\n",
       "      <td>0.389530</td>\n",
       "      <td>-0.137472</td>\n",
       "      <td>0.523102</td>\n",
       "      <td>1.365255</td>\n",
       "      <td>0.900301</td>\n",
       "      <td>-0.881982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108497</td>\n",
       "      <td>0.167389</td>\n",
       "      <td>0.243849</td>\n",
       "      <td>-0.900453</td>\n",
       "      <td>-0.658484</td>\n",
       "      <td>-1.208010</td>\n",
       "      <td>-0.604155</td>\n",
       "      <td>0.118649</td>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0033798e-430e-4aa1-a401-30db51622847</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.092653</td>\n",
       "      <td>-0.665319</td>\n",
       "      <td>-0.183638</td>\n",
       "      <td>1.374086</td>\n",
       "      <td>0.372929</td>\n",
       "      <td>-0.956860</td>\n",
       "      <td>0.202154</td>\n",
       "      <td>-0.733449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.431990</td>\n",
       "      <td>2.080202</td>\n",
       "      <td>1.475127</td>\n",
       "      <td>-0.129252</td>\n",
       "      <td>0.719002</td>\n",
       "      <td>1.130040</td>\n",
       "      <td>0.817440</td>\n",
       "      <td>0.595391</td>\n",
       "      <td>161</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                game_id  innings  \\\n",
       "0  0021ca69-72b5-4080-9e2e-f7cd9e558b47        1   \n",
       "1  0021ca69-72b5-4080-9e2e-f7cd9e558b47        2   \n",
       "2  002795ac-3340-4ccf-9763-865ab0fb8268        1   \n",
       "3  002795ac-3340-4ccf-9763-865ab0fb8268        2   \n",
       "4  0033798e-430e-4aa1-a401-30db51622847        1   \n",
       "\n",
       "   total_batter_runs_conceded_mean  total_runs_from_relevant_extras_mean  \\\n",
       "0                         1.060670                             -0.513670   \n",
       "1                         0.861048                              0.147495   \n",
       "2                         0.197794                              2.108226   \n",
       "3                         0.275919                              0.611244   \n",
       "4                        -0.092653                             -0.665319   \n",
       "\n",
       "   total_total_runs_conceded_mean  total_taken_from_relevant_wickets_mean  \\\n",
       "0                        1.011385                               -0.551914   \n",
       "1                        0.893025                                0.872679   \n",
       "2                        0.479992                                0.819249   \n",
       "3                        0.389530                               -0.137472   \n",
       "4                       -0.183638                                1.374086   \n",
       "\n",
       "   powerplay_batter_runs_conceded_mean  \\\n",
       "0                             0.691736   \n",
       "1                             0.559383   \n",
       "2                            -0.584629   \n",
       "3                             0.523102   \n",
       "4                             0.372929   \n",
       "\n",
       "   powerplay_runs_from_relevant_extras_mean  \\\n",
       "0                                 -0.427798   \n",
       "1                                 -0.006142   \n",
       "2                                  1.416903   \n",
       "3                                  1.365255   \n",
       "4                                 -0.956860   \n",
       "\n",
       "   powerplay_total_runs_conceded_mean  \\\n",
       "0                            0.586786   \n",
       "1                            0.576349   \n",
       "2                           -0.411425   \n",
       "3                            0.900301   \n",
       "4                            0.202154   \n",
       "\n",
       "   powerplay_taken_from_relevant_wickets_mean  ...  \\\n",
       "0                                   -0.163023  ...   \n",
       "1                                    1.455650  ...   \n",
       "2                                    1.396177  ...   \n",
       "3                                   -0.881982  ...   \n",
       "4                                   -0.733449  ...   \n",
       "\n",
       "   powerplay_runs_batter_mean  powerplay_high_scoring_hit_mean  \\\n",
       "0                    0.906615                         1.147216   \n",
       "1                    0.711668                         0.555493   \n",
       "2                    0.255541                         0.150034   \n",
       "3                    0.108497                         0.167389   \n",
       "4                    1.431990                         2.080202   \n",
       "\n",
       "   powerplay_total_mean  powerplay_is_wicket_mean  \\\n",
       "0              0.869648                 -0.755857   \n",
       "1              0.538625                 -0.559719   \n",
       "2              0.399280                  0.147236   \n",
       "3              0.243849                 -0.900453   \n",
       "4              1.475127                 -0.129252   \n",
       "\n",
       "   non_powerplay_runs_batter_mean  non_powerplay_high_scoring_hit_mean  \\\n",
       "0                        0.516191                             0.368048   \n",
       "1                        0.789972                             0.555270   \n",
       "2                        0.737713                             0.817304   \n",
       "3                       -0.658484                            -1.208010   \n",
       "4                        0.719002                             1.130040   \n",
       "\n",
       "   non_powerplay_total_mean  non_powerplay_is_wicket_mean  final_runs  \\\n",
       "0                  0.520429                      0.395600         170   \n",
       "1                  0.796122                     -0.310116         147   \n",
       "2                  1.010981                      0.106142         136   \n",
       "3                 -0.604155                      0.118649         120   \n",
       "4                  0.817440                      0.595391         161   \n",
       "\n",
       "   final_wickets  \n",
       "0              6  \n",
       "1             10  \n",
       "2             10  \n",
       "3              7  \n",
       "4              9  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/saved_data/standardized_per_game_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7533 entries, 0 to 7532\n",
      "Data columns (total 28 columns):\n",
      " #   Column                                          Non-Null Count  Dtype  \n",
      "---  ------                                          --------------  -----  \n",
      " 0   game_id                                         7533 non-null   object \n",
      " 1   innings                                         7533 non-null   int64  \n",
      " 2   total_batter_runs_conceded_mean                 7533 non-null   float64\n",
      " 3   total_runs_from_relevant_extras_mean            7533 non-null   float64\n",
      " 4   total_total_runs_conceded_mean                  7533 non-null   float64\n",
      " 5   total_taken_from_relevant_wickets_mean          7533 non-null   float64\n",
      " 6   powerplay_batter_runs_conceded_mean             7533 non-null   float64\n",
      " 7   powerplay_runs_from_relevant_extras_mean        7533 non-null   float64\n",
      " 8   powerplay_total_runs_conceded_mean              7533 non-null   float64\n",
      " 9   powerplay_taken_from_relevant_wickets_mean      7533 non-null   float64\n",
      " 10  non_powerplay_batter_runs_conceded_mean         7532 non-null   float64\n",
      " 11  non_powerplay_runs_from_relevant_extras_mean    7532 non-null   float64\n",
      " 12  non_powerplay_total_runs_conceded_mean          7532 non-null   float64\n",
      " 13  non_powerplay_taken_from_relevant_wickets_mean  7532 non-null   float64\n",
      " 14  total_runs_batter_mean                          7533 non-null   float64\n",
      " 15  total_high_scoring_hit_mean                     7533 non-null   float64\n",
      " 16  total_total_mean                                7533 non-null   float64\n",
      " 17  total_is_wicket_mean                            7533 non-null   float64\n",
      " 18  powerplay_runs_batter_mean                      7533 non-null   float64\n",
      " 19  powerplay_high_scoring_hit_mean                 7533 non-null   float64\n",
      " 20  powerplay_total_mean                            7533 non-null   float64\n",
      " 21  powerplay_is_wicket_mean                        7533 non-null   float64\n",
      " 22  non_powerplay_runs_batter_mean                  7533 non-null   float64\n",
      " 23  non_powerplay_high_scoring_hit_mean             7533 non-null   float64\n",
      " 24  non_powerplay_total_mean                        7533 non-null   float64\n",
      " 25  non_powerplay_is_wicket_mean                    7533 non-null   float64\n",
      " 26  final_runs                                      7533 non-null   int64  \n",
      " 27  final_wickets                                   7533 non-null   int64  \n",
      "dtypes: float64(24), int64(3), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's one game missing non-powerplay stats, so I will drop that game.\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate test data for final evaluation\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "test_data.to_csv('../data/saved_data/match_test_data.csv', index=False)\n",
    "data = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_estimation_df = data.drop(columns=['game_id', 'innings', 'final_wickets'])\n",
    "wicket_estimation_df = data.drop(columns=['game_id', 'innings', 'final_runs'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "For my baseline I am going to use linear regression. I will use RFE for feature selection.\n",
    "\n",
    "I belive innings score is given as runs and wickets, so I will train two models, one to predict runs and one to predict wickets. I will do these seperately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(run_estimation_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Rankings:\n",
      "                                           Feature  Ranking\n",
      "0                  total_batter_runs_conceded_mean        1\n",
      "13                     total_high_scoring_hit_mean        1\n",
      "12                          total_runs_batter_mean        1\n",
      "22                        non_powerplay_total_mean        1\n",
      "17                 powerplay_high_scoring_hit_mean        1\n",
      "20                  non_powerplay_runs_batter_mean        1\n",
      "18                            powerplay_total_mean        1\n",
      "21             non_powerplay_high_scoring_hit_mean        1\n",
      "2                   total_total_runs_conceded_mean        1\n",
      "1             total_runs_from_relevant_extras_mean        1\n",
      "15                            total_is_wicket_mean        2\n",
      "16                      powerplay_runs_batter_mean        3\n",
      "4              powerplay_batter_runs_conceded_mean        4\n",
      "9     non_powerplay_runs_from_relevant_extras_mean        5\n",
      "6               powerplay_total_runs_conceded_mean        6\n",
      "5         powerplay_runs_from_relevant_extras_mean        7\n",
      "10          non_powerplay_total_runs_conceded_mean        8\n",
      "8          non_powerplay_batter_runs_conceded_mean        9\n",
      "14                                total_total_mean       10\n",
      "23                    non_powerplay_is_wicket_mean       11\n",
      "19                        powerplay_is_wicket_mean       12\n",
      "7       powerplay_taken_from_relevant_wickets_mean       13\n",
      "11  non_powerplay_taken_from_relevant_wickets_mean       14\n",
      "3           total_taken_from_relevant_wickets_mean       15\n"
     ]
    }
   ],
   "source": [
    "def initial_feature_selection(df, n_features_to_select=10, target_column='final_runs'):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    estimator = LinearRegression()\n",
    "    \n",
    "    selector = RFE(estimator=estimator, \n",
    "                  n_features_to_select=n_features_to_select,\n",
    "                  step=1)\n",
    "    selector = selector.fit(X, y)\n",
    "    \n",
    "    selected_features = X.columns[selector.support_].tolist()\n",
    "    \n",
    "    feature_ranking = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Ranking': selector.ranking_\n",
    "    }).sort_values('Ranking')\n",
    "    print(\"Feature Rankings:\")\n",
    "    print(feature_ranking)\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "important_features = initial_feature_selection(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>total_total_runs_conceded_mean</td>\n",
       "      <td>0.984783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>0.767626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>0.722504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>non_powerplay_runs_batter_mean</td>\n",
       "      <td>0.741551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>non_powerplay_total_mean</td>\n",
       "      <td>0.731489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_total_runs_conceded_mean</td>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>0.733432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_total_runs_conceded_mean</td>\n",
       "      <td>non_powerplay_runs_batter_mean</td>\n",
       "      <td>0.708200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_total_runs_conceded_mean</td>\n",
       "      <td>non_powerplay_total_mean</td>\n",
       "      <td>0.710996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>0.963584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>powerplay_high_scoring_hit_mean</td>\n",
       "      <td>0.866549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>powerplay_total_mean</td>\n",
       "      <td>0.872979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>non_powerplay_runs_batter_mean</td>\n",
       "      <td>0.978426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>non_powerplay_high_scoring_hit_mean</td>\n",
       "      <td>0.922893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>non_powerplay_total_mean</td>\n",
       "      <td>0.969951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>powerplay_high_scoring_hit_mean</td>\n",
       "      <td>0.894925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>powerplay_total_mean</td>\n",
       "      <td>0.874352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>non_powerplay_runs_batter_mean</td>\n",
       "      <td>0.945162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>non_powerplay_high_scoring_hit_mean</td>\n",
       "      <td>0.951960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>non_powerplay_total_mean</td>\n",
       "      <td>0.942332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>powerplay_high_scoring_hit_mean</td>\n",
       "      <td>powerplay_total_mean</td>\n",
       "      <td>0.958962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>powerplay_high_scoring_hit_mean</td>\n",
       "      <td>non_powerplay_runs_batter_mean</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>powerplay_high_scoring_hit_mean</td>\n",
       "      <td>non_powerplay_high_scoring_hit_mean</td>\n",
       "      <td>0.791293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>powerplay_high_scoring_hit_mean</td>\n",
       "      <td>non_powerplay_total_mean</td>\n",
       "      <td>0.807830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>powerplay_total_mean</td>\n",
       "      <td>non_powerplay_runs_batter_mean</td>\n",
       "      <td>0.818081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>powerplay_total_mean</td>\n",
       "      <td>non_powerplay_high_scoring_hit_mean</td>\n",
       "      <td>0.781763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>powerplay_total_mean</td>\n",
       "      <td>non_powerplay_total_mean</td>\n",
       "      <td>0.822836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>non_powerplay_runs_batter_mean</td>\n",
       "      <td>non_powerplay_high_scoring_hit_mean</td>\n",
       "      <td>0.952410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>non_powerplay_runs_batter_mean</td>\n",
       "      <td>non_powerplay_total_mean</td>\n",
       "      <td>0.992652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>non_powerplay_high_scoring_hit_mean</td>\n",
       "      <td>non_powerplay_total_mean</td>\n",
       "      <td>0.954465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               feature1                             feature2  \\\n",
       "0       total_batter_runs_conceded_mean       total_total_runs_conceded_mean   \n",
       "1       total_batter_runs_conceded_mean               total_runs_batter_mean   \n",
       "2       total_batter_runs_conceded_mean          total_high_scoring_hit_mean   \n",
       "3       total_batter_runs_conceded_mean       non_powerplay_runs_batter_mean   \n",
       "4       total_batter_runs_conceded_mean             non_powerplay_total_mean   \n",
       "5        total_total_runs_conceded_mean               total_runs_batter_mean   \n",
       "6        total_total_runs_conceded_mean       non_powerplay_runs_batter_mean   \n",
       "7        total_total_runs_conceded_mean             non_powerplay_total_mean   \n",
       "8                total_runs_batter_mean          total_high_scoring_hit_mean   \n",
       "9                total_runs_batter_mean      powerplay_high_scoring_hit_mean   \n",
       "10               total_runs_batter_mean                 powerplay_total_mean   \n",
       "11               total_runs_batter_mean       non_powerplay_runs_batter_mean   \n",
       "12               total_runs_batter_mean  non_powerplay_high_scoring_hit_mean   \n",
       "13               total_runs_batter_mean             non_powerplay_total_mean   \n",
       "14          total_high_scoring_hit_mean      powerplay_high_scoring_hit_mean   \n",
       "15          total_high_scoring_hit_mean                 powerplay_total_mean   \n",
       "16          total_high_scoring_hit_mean       non_powerplay_runs_batter_mean   \n",
       "17          total_high_scoring_hit_mean  non_powerplay_high_scoring_hit_mean   \n",
       "18          total_high_scoring_hit_mean             non_powerplay_total_mean   \n",
       "19      powerplay_high_scoring_hit_mean                 powerplay_total_mean   \n",
       "20      powerplay_high_scoring_hit_mean       non_powerplay_runs_batter_mean   \n",
       "21      powerplay_high_scoring_hit_mean  non_powerplay_high_scoring_hit_mean   \n",
       "22      powerplay_high_scoring_hit_mean             non_powerplay_total_mean   \n",
       "23                 powerplay_total_mean       non_powerplay_runs_batter_mean   \n",
       "24                 powerplay_total_mean  non_powerplay_high_scoring_hit_mean   \n",
       "25                 powerplay_total_mean             non_powerplay_total_mean   \n",
       "26       non_powerplay_runs_batter_mean  non_powerplay_high_scoring_hit_mean   \n",
       "27       non_powerplay_runs_batter_mean             non_powerplay_total_mean   \n",
       "28  non_powerplay_high_scoring_hit_mean             non_powerplay_total_mean   \n",
       "\n",
       "    correlation  \n",
       "0      0.984783  \n",
       "1      0.767626  \n",
       "2      0.722504  \n",
       "3      0.741551  \n",
       "4      0.731489  \n",
       "5      0.733432  \n",
       "6      0.708200  \n",
       "7      0.710996  \n",
       "8      0.963584  \n",
       "9      0.866549  \n",
       "10     0.872979  \n",
       "11     0.978426  \n",
       "12     0.922893  \n",
       "13     0.969951  \n",
       "14     0.894925  \n",
       "15     0.874352  \n",
       "16     0.945162  \n",
       "17     0.951960  \n",
       "18     0.942332  \n",
       "19     0.958962  \n",
       "20     0.813067  \n",
       "21     0.791293  \n",
       "22     0.807830  \n",
       "23     0.818081  \n",
       "24     0.781763  \n",
       "25     0.822836  \n",
       "26     0.952410  \n",
       "27     0.992652  \n",
       "28     0.954465  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_correlations(df, features):\n",
    "    corr_matrix = df[features].corr()\n",
    "    \n",
    "    # Find highly correlated \n",
    "    high_corr = []\n",
    "    for i in range(len(features)):\n",
    "        for j in range(i+1, len(features)):\n",
    "            if abs(corr_matrix.iloc[i,j]) > 0.7:\n",
    "                high_corr.append({\n",
    "                    'feature1': features[i],\n",
    "                    'feature2': features[j],\n",
    "                    'correlation': corr_matrix.iloc[i,j]\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(high_corr)\n",
    "\n",
    "# Use it\n",
    "correlations = check_correlations(train_data, important_features)\n",
    "print(\"Highly correlated features:\")\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evnident that there is significant correlation between several of the best ranked features, likely stemming from the fact that total stats encompass powerplay and non-powerplay stats. I am going to start by only keeping the total stats for now.\n",
    "\n",
    "Since I would be eliminating a large chunk of the 'important_features' I will start again from scratch with only the total stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [col for col in run_estimation_df.columns if 'total' in col[:5]] + ['final_runs']\n",
    "totals_run_estimation_df = run_estimation_df[cols_to_keep]\n",
    "\n",
    "train_data, test_data = train_test_split(totals_run_estimation_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Rankings:\n",
      "                                  Feature  Ranking\n",
      "0         total_batter_runs_conceded_mean        1\n",
      "1    total_runs_from_relevant_extras_mean        1\n",
      "2          total_total_runs_conceded_mean        1\n",
      "3  total_taken_from_relevant_wickets_mean        1\n",
      "4                  total_runs_batter_mean        1\n",
      "5             total_high_scoring_hit_mean        1\n",
      "6                        total_total_mean        1\n",
      "7                    total_is_wicket_mean        1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eden/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/feature_selection/_rfe.py:291: UserWarning: Found n_features_to_select=10 > n_features=8. There will be no feature selection and all features will be kept.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "important_features = initial_feature_selection(train_data, target_column='final_runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE does not work with <10 features. That being said barring any significant correlations I don't think I have an amount that should negatively impact the model so I will keep all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1</th>\n",
       "      <th>feature2</th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>total_total_runs_conceded_mean</td>\n",
       "      <td>0.984783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>0.767626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>0.722504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>total_batter_runs_conceded_mean</td>\n",
       "      <td>total_total_mean</td>\n",
       "      <td>0.760415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_total_runs_conceded_mean</td>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>0.733432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>total_total_runs_conceded_mean</td>\n",
       "      <td>total_total_mean</td>\n",
       "      <td>0.739177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>0.963584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>total_runs_batter_mean</td>\n",
       "      <td>total_total_mean</td>\n",
       "      <td>0.993446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_high_scoring_hit_mean</td>\n",
       "      <td>total_total_mean</td>\n",
       "      <td>0.964398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature1                        feature2  \\\n",
       "0  total_batter_runs_conceded_mean  total_total_runs_conceded_mean   \n",
       "1  total_batter_runs_conceded_mean          total_runs_batter_mean   \n",
       "2  total_batter_runs_conceded_mean     total_high_scoring_hit_mean   \n",
       "3  total_batter_runs_conceded_mean                total_total_mean   \n",
       "4   total_total_runs_conceded_mean          total_runs_batter_mean   \n",
       "5   total_total_runs_conceded_mean                total_total_mean   \n",
       "6           total_runs_batter_mean     total_high_scoring_hit_mean   \n",
       "7           total_runs_batter_mean                total_total_mean   \n",
       "8      total_high_scoring_hit_mean                total_total_mean   \n",
       "\n",
       "   correlation  \n",
       "0     0.984783  \n",
       "1     0.767626  \n",
       "2     0.722504  \n",
       "3     0.760415  \n",
       "4     0.733432  \n",
       "5     0.739177  \n",
       "6     0.963584  \n",
       "7     0.993446  \n",
       "8     0.964398  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlations = check_correlations(train_data, important_features)\n",
    "correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so... there are a lot of high correlations, but a couple very high ones.\n",
    "- The mean runs conceded and the mean batter only runs conceded are highly very highly correlated, likely due to the fact that most of the runs conceded are batter runs and not extras.\n",
    "- the mean runs conceded scored by the batter is very highly correlated with:\n",
    "    - the mean no. of high scoring balls hit\n",
    "    - the mean total runs made by the batting side including batter runs and extras.\n",
    "- Finally the mean total runs scored is highly correlated with the mean no. of high scoring balls hit.\n",
    "\n",
    "Based on this, I will remove:\n",
    "- The mean total runs conceded per game\n",
    "- The mean number of high scoring balls hit per game\n",
    "- The mean runs scored by the batting side per game\n",
    "\n",
    "For the sake of clarity I will also rename the existing features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['total_batter_runs_conceded_mean',\n",
       "       'total_runs_from_relevant_extras_mean',\n",
       "       'total_taken_from_relevant_wickets_mean', 'total_runs_batter_mean',\n",
       "       'total_is_wicket_mean', 'final_runs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.drop(columns=['total_total_runs_conceded_mean', 'total_total_mean', 'total_high_scoring_hit_mean'])\n",
    "test_data = test_data.drop(columns=['total_total_runs_conceded_mean', 'total_total_mean', 'total_high_scoring_hit_mean'])\n",
    "\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_batter_runs_conceded', 'mean_extras_runs_conceded',\n",
       "       'mean_wickets_taken', 'mean_batter_runs_scored',\n",
       "       'mean_wickets_conceded', 'final_runs'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_rename = {\n",
    "    'total_batter_runs_conceded_mean': 'mean_batter_runs_conceded',\n",
    "    'total_runs_from_relevant_extras_mean': 'mean_extras_runs_conceded',\n",
    "    'total_taken_from_relevant_wickets_mean': 'mean_wickets_taken',\n",
    "    'total_runs_batter_mean': 'mean_batter_runs_scored',\n",
    "    'total_is_wicket_mean': 'mean_wickets_conceded'\n",
    "}\n",
    "\n",
    "train_data.rename(columns=cols_to_rename, inplace=True)\n",
    "test_data.rename(columns=cols_to_rename, inplace=True)\n",
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Train R²: 0.456\n",
      "Test R²: 0.456\n",
      "Train RMSE: 32.589\n",
      "Test RMSE: 32.774\n",
      "Train MAPE: 0.306\n",
      "Test MAPE: 0.282\n",
      "\n",
      "Feature Coefficients:\n",
      "                     Feature  Coefficient\n",
      "0  mean_batter_runs_conceded    11.130904\n",
      "1  mean_extras_runs_conceded     6.829709\n",
      "2         mean_wickets_taken    -0.660033\n",
      "3    mean_batter_runs_scored    20.373649\n",
      "4      mean_wickets_conceded    -5.456100\n"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate_baseline_model(train_data, test_data, target_column):\n",
    "    X_train = train_data.drop(columns=[target_column])\n",
    "    y_train = train_data[target_column]\n",
    "    X_test = test_data.drop(columns=[target_column])\n",
    "    y_test = test_data[target_column]\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    metrics = {\n",
    "        'train': {\n",
    "            'r2': r2_score(y_train, y_pred_train),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_train, y_pred_train)),\n",
    "            'mape': mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "        },\n",
    "        'test': {\n",
    "            'r2': r2_score(y_test, y_pred_test),\n",
    "            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_test)),\n",
    "            'mape': mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "        }\n",
    "    }\n",
    "    coefficients = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Coefficient': model.coef_\n",
    "    })\n",
    "    \n",
    "    print(\"Model Performance:\")\n",
    "    print(f\"Train R²: {metrics['train']['r2']:.3f}\")\n",
    "    print(f\"Test R²: {metrics['train']['r2']:.3f}\")\n",
    "    print(f\"Train RMSE: {metrics['train']['rmse']:.3f}\")\n",
    "    print(f\"Test RMSE: {metrics['test']['rmse']:.3f}\")\n",
    "    print(f\"Train MAPE: {metrics['train']['mape']:.3f}\")\n",
    "    print(f\"Test MAPE: {metrics['test']['mape']:.3f}\")\n",
    "    print(\"\\nFeature Coefficients:\")\n",
    "    print(coefficients)\n",
    "    \n",
    "    return model, metrics, coefficients\n",
    "\n",
    "model, metrics, coefficients = train_and_evaluate_baseline_model(train_data, test_data, 'final_runs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... The model is not great - but that's fine for a baseline.\n",
    "\n",
    "The similar test and train results suggest no overfitting, though considering the number of features and the model itself this was unlikely anyway.\n",
    "\n",
    "The R^2 is 0.446 which is not great, suggests out baseline struggled to fit the data well.\n",
    "\n",
    "The MAPE is 0.301, suggesting that while the model is not great, it is faily okay for getting a ballpark estimation... \n",
    "\n",
    "Anyways, time to improve on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "I am going to try an approach using tree based models to see if they can improve results over simple linear regression.\n",
    "\n",
    "I will start with a random forest model.\n",
    "\n",
    "Since random forest is not significantly affected by multicollinearity, I will keep the original feature set as it should filter what it believes is most important/informative at each step. Depending on performance however I may then try removing some features.\n",
    "\n",
    "I will be using a train/valid/test split this time as there are some hyperparameters to tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run_estimation_df\n",
    "target_column = 'final_runs'\n",
    "test_size = 0.15\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "X = data.drop(columns=[target_column])\n",
    "y = data[target_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=random_state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_random_forest(X_train, y_train, cv=5, random_state=42, **kwargs):\n",
    "    model = RandomForestRegressor(random_state=random_state, **kwargs)\n",
    "    \n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring={\n",
    "            'r2': 'r2',\n",
    "            'rmse': 'neg_root_mean_squared_error',\n",
    "            'mape': 'neg_mean_absolute_percentage_error'\n",
    "        },\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    analysis = {\n",
    "        'r2': {\n",
    "            'train_avg': cv_results['train_r2'].mean(),\n",
    "            'train_std': cv_results['train_r2'].std(),\n",
    "            'cv_avg': cv_results['test_r2'].mean(),\n",
    "            'cv_std': cv_results['test_r2'].std(),\n",
    "            'gap': cv_results['train_r2'].mean() - cv_results['test_r2'].mean(),\n",
    "            'consistency': 'Stable' if cv_results['test_r2'].std() < 0.05 else 'Unstable'\n",
    "        },\n",
    "        'rmse': {\n",
    "            'train_avg': -cv_results['train_rmse'].mean(),\n",
    "            'train_std': cv_results['train_rmse'].std(),\n",
    "            'cv_avg': -cv_results['test_rmse'].mean(),\n",
    "            'cv_std': cv_results['test_rmse'].std(),\n",
    "            'gap': -cv_results['test_rmse'].mean() - (-cv_results['train_rmse'].mean())\n",
    "        },\n",
    "        'mape': {\n",
    "            'train_avg': -cv_results['train_mape'].mean(),\n",
    "            'train_std': cv_results['train_mape'].std(),\n",
    "            'cv_avg': -cv_results['test_mape'].mean(),\n",
    "            'cv_std': cv_results['test_mape'].std(),\n",
    "            'gap': -cv_results['test_mape'].mean() - (-cv_results['train_mape'].mean())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    print(\"Cross-Validation Analysis:\")\n",
    "    print(\"\\nR² Scores:\")\n",
    "    print(f\"Training Average: {analysis['r2']['train_avg']:.3f} ± {analysis['r2']['train_std']:.3f}\")\n",
    "    print(f\"CV Average: {analysis['r2']['cv_avg']:.3f} ± {analysis['r2']['cv_std']:.3f}\")\n",
    "    print(f\"Gap (Train-CV): {analysis['r2']['gap']:.3f}\")\n",
    "    print(f\"CV Consistency: {analysis['r2']['consistency']}\")\n",
    "    \n",
    "    print(\"\\nRMSE Scores:\")\n",
    "    print(f\"Training Average: {analysis['rmse']['train_avg']:.3f} ± {analysis['rmse']['train_std']:.3f}\")\n",
    "    print(f\"CV Average: {analysis['rmse']['cv_avg']:.3f} ± {analysis['rmse']['cv_std']:.3f}\")\n",
    "    print(f\"Gap (CV-Train): {analysis['rmse']['gap']:.3f}\")\n",
    "    \n",
    "    print(\"\\nMAPE Scores:\")\n",
    "    print(f\"Training Average: {analysis['mape']['train_avg']:.3f} ± {analysis['mape']['train_std']:.3f}\")\n",
    "    print(f\"CV Average: {analysis['mape']['cv_avg']:.3f} ± {analysis['mape']['cv_std']:.3f}\")\n",
    "    print(f\"Gap (CV-Train): {analysis['mape']['gap']:.3f}\")\n",
    "    \n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return model, analysis, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.926 ± 0.001\n",
      "CV Average: 0.472 ± 0.016\n",
      "Gap (Train-CV): 0.454\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 12.070 ± 0.092\n",
      "CV Average: 32.132 ± 0.509\n",
      "Gap (CV-Train): 20.061\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 0.111 ± 0.004\n",
      "CV Average: 0.295 ± 0.040\n",
      "Gap (CV-Train): 0.184\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                                           Feature  Importance\n",
      "22                        non_powerplay_total_mean    0.328556\n",
      "14                                total_total_mean    0.115499\n",
      "10          non_powerplay_total_runs_conceded_mean    0.039960\n",
      "2                   total_total_runs_conceded_mean    0.035861\n",
      "5         powerplay_runs_from_relevant_extras_mean    0.034760\n",
      "15                            total_is_wicket_mean    0.034508\n",
      "1             total_runs_from_relevant_extras_mean    0.031531\n",
      "11  non_powerplay_taken_from_relevant_wickets_mean    0.029799\n",
      "9     non_powerplay_runs_from_relevant_extras_mean    0.029393\n",
      "8          non_powerplay_batter_runs_conceded_mean    0.028445\n"
     ]
    }
   ],
   "source": [
    "model, analysis, feature_importance = do_random_forest(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... with no tuning the model is not great. It is able to fit the training data very well, but the CV gap demonstrates that there is significant overfitting going on. In fact, we see scores that are marginally worse than the baseline model.\n",
    "\n",
    "I am going to begin by seeing how much I can improve the model by tuning the hyperparameters. Hopefully automated tuning should help a decent amount, followed by manual tuning depending on results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_random_forest(X_train, y_train):    \n",
    "    param_grid = {\n",
    "        'max_depth': [10, 20, 30, 50, 100, None],\n",
    "        'min_samples_split': [2, 5, 10, 20, 50],\n",
    "        'min_samples_leaf': [1, 2, 4, 8, 16],\n",
    "        'n_estimators': [100, 200, 300, 400, 500],\n",
    "        'max_features': ['sqrt', 'log2', None]\n",
    "    }\n",
    "    \n",
    "    search = RandomizedSearchCV(\n",
    "        RandomForestRegressor(random_state=42),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    best_model = search.best_estimator_\n",
    "    final_score = best_model.score(X_train, y_train)\n",
    "    \n",
    "    print(\"Best parameters:\", search.best_params_)\n",
    "    print(\"CV Score:\", search.best_score_)\n",
    "    print(\"Final Score:\", final_score)\n",
    "    \n",
    "    return best_model, search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   3.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   3.9s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   4.0s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   4.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   4.0s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   5.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.2s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=50, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=50, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   6.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=50, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=50, n_estimators=500; total time=   5.9s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=50, n_estimators=500; total time=   6.1s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=300; total time=  18.2s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=300; total time=  19.0s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=300; total time=  18.8s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=2, min_samples_split=20, n_estimators=100; total time=   7.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=50, n_estimators=500; total time=  33.1s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=50, n_estimators=500; total time=  33.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=50, n_estimators=500; total time=  34.6s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=50, n_estimators=500; total time=  34.4s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=50, n_estimators=500; total time=  34.3s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=2, min_samples_split=20, n_estimators=100; total time=   7.5s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=2, min_samples_split=20, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=300; total time=  19.2s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=20, n_estimators=500; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=20, n_estimators=500; total time=   4.8s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=300; total time=  19.1s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=2, min_samples_split=20, n_estimators=100; total time=   7.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=20, n_estimators=500; total time=   4.6s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=20, n_estimators=500; total time=   4.6s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   2.9s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=2, min_samples_split=20, n_estimators=100; total time=   7.8s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=20, n_estimators=500; total time=   4.7s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.0s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=5, n_estimators=500; total time=   4.7s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=5, n_estimators=500; total time=   4.7s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=5, n_estimators=500; total time=   5.0s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=5, n_estimators=500; total time=   4.9s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=5, n_estimators=500; total time=   4.9s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.5s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   5.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   4.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=5, n_estimators=400; total time=   4.6s\n",
      "Best parameters: {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': None}\n",
      "CV Score: 0.4799384928698152\n",
      "Final Score: 0.8750262153226489\n"
     ]
    }
   ],
   "source": [
    "best_rf, kwargs = tune_random_forest(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.873 ± 0.002\n",
      "CV Average: 0.480 ± 0.017\n",
      "Gap (Train-CV): 0.393\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 15.754 ± 0.073\n",
      "CV Average: 31.884 ± 0.516\n",
      "Gap (CV-Train): 16.130\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 0.147 ± 0.006\n",
      "CV Average: 0.297 ± 0.039\n",
      "Gap (CV-Train): 0.149\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                                    Feature  Importance\n",
      "22                 non_powerplay_total_mean    0.097153\n",
      "14                         total_total_mean    0.096426\n",
      "20           non_powerplay_runs_batter_mean    0.076919\n",
      "12                   total_runs_batter_mean    0.073876\n",
      "13              total_high_scoring_hit_mean    0.063561\n",
      "21      non_powerplay_high_scoring_hit_mean    0.056652\n",
      "2            total_total_runs_conceded_mean    0.045199\n",
      "18                     powerplay_total_mean    0.041084\n",
      "10   non_powerplay_total_runs_conceded_mean    0.040734\n",
      "8   non_powerplay_batter_runs_conceded_mean    0.040404\n"
     ]
    }
   ],
   "source": [
    "model, analysis, feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the earlier results, we see very little improvement. The CV gap has been reduced, however the actual scores are only very marginally imroved. This suggests that the model is overfitting less, but this is not leading to an improvement in the model's ability to predict new data. \n",
    "\n",
    "I am going to try some extremenly agressive hyperparameter values to see if it helps. I expect they may reduce overfitting, but I doubt they will improve the model's overall performance. Possibly worth a shot though"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.668 ± 0.002\n",
      "CV Average: 0.476 ± 0.014\n",
      "Gap (Train-CV): 0.192\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 25.504 ± 0.116\n",
      "CV Average: 32.007 ± 0.486\n",
      "Gap (CV-Train): 6.503\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 0.235 ± 0.007\n",
      "CV Average: 0.299 ± 0.038\n",
      "Gap (CV-Train): 0.065\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                                    Feature  Importance\n",
      "22                 non_powerplay_total_mean    0.118805\n",
      "14                         total_total_mean    0.114493\n",
      "20           non_powerplay_runs_batter_mean    0.094458\n",
      "12                   total_runs_batter_mean    0.089984\n",
      "13              total_high_scoring_hit_mean    0.074657\n",
      "21      non_powerplay_high_scoring_hit_mean    0.065176\n",
      "2            total_total_runs_conceded_mean    0.046585\n",
      "10   non_powerplay_total_runs_conceded_mean    0.042021\n",
      "18                     powerplay_total_mean    0.040333\n",
      "8   non_powerplay_batter_runs_conceded_mean    0.035816\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 5,\n",
    "    'n_estimators': 500,\n",
    "    'max_features': 'log2'\n",
    "}\n",
    "model, analysis, feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turns out my hypothesis was indeed correct, the model is overfitting far less, however the scores have not really improved.\n",
    "I will finally use this final model with my test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance:\n",
      "R²: 0.449\n",
      "RMSE: 32.648\n",
      "MAPE: 0.287\n"
     ]
    }
   ],
   "source": [
    "def test_final_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    print(\"Final Model Performance:\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "    print(f\"RMSE: {rmse:.3f}\")\n",
    "    print(f\"MAPE: {mape:.3f}\")\n",
    "    return r2, rmse, mape\n",
    "\n",
    "r2, rmse, mape = test_final_model(best_rf, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/match_models/run_model.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_rf, '../models/match_models/run_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the baseline model, we do see improvements in all values, albeit not significant ones. MAPE is 0.265 compared to 0.301, RMSE 31.3 compared to 33.4 and R^2 is 0.504 compared to 0.446.\n",
    "\n",
    "I would however like to repeat this with only the total features. While random forest should filter out features itself, I am curious to see how it will affect performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {\n",
    "    'total_batter_runs_conceded_mean': 'mean_batter_runs_conceded',\n",
    "    'total_runs_from_relevant_extras_mean': 'mean_extras_runs_conceded',\n",
    "    'total_taken_from_relevant_wickets_mean': 'mean_wickets_taken',\n",
    "    'total_runs_batter_mean': 'mean_batter_runs_scored',\n",
    "    'total_is_wicket_mean': 'mean_wickets_conceded'\n",
    "}\n",
    "\n",
    "data = totals_run_estimation_df.drop(columns=['total_total_runs_conceded_mean', 'total_total_mean', 'total_high_scoring_hit_mean']) \\\n",
    "                               .rename(columns=cols_to_rename)\n",
    "\n",
    "X = data.drop(columns=['final_runs'])\n",
    "y = data['final_runs']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.920 ± 0.001\n",
      "CV Average: 0.435 ± 0.007\n",
      "Gap (Train-CV): 0.485\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 12.497 ± 0.067\n",
      "CV Average: 33.177 ± 0.664\n",
      "Gap (CV-Train): 20.681\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 0.114 ± 0.003\n",
      "CV Average: 0.306 ± 0.038\n",
      "Gap (CV-Train): 0.192\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                     Feature  Importance\n",
      "3    mean_batter_runs_scored    0.497249\n",
      "0  mean_batter_runs_conceded    0.143924\n",
      "1  mean_extras_runs_conceded    0.137422\n",
      "2         mean_wickets_taken    0.111080\n",
      "4      mean_wickets_conceded    0.110324\n"
     ]
    }
   ],
   "source": [
    "model, analysis, feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intereestingly, we see marginally worse results than using all features with no hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.4s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.6s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=   1.7s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=16, min_samples_split=50, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=16, min_samples_split=50, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=16, min_samples_split=50, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=16, min_samples_split=50, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=16, min_samples_split=50, n_estimators=100; total time=   0.5s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.5s\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=100, max_features=log2, min_samples_leaf=16, min_samples_split=2, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=16, min_samples_split=50, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=16, min_samples_split=50, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=16, min_samples_split=50, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=16, min_samples_split=50, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=16, min_samples_split=50, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=10, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=10, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=10, n_estimators=500; total time=   2.5s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=10, n_estimators=500; total time=   2.3s\n",
      "[CV] END max_depth=10, max_features=log2, min_samples_leaf=16, min_samples_split=10, n_estimators=500; total time=   2.4s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=200; total time=   1.0s\n",
      "[CV] END max_depth=100, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=400; total time=   5.3s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=400; total time=   5.2s\n",
      "[CV] END max_depth=30, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=400; total time=   5.1s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   2.1s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   1.7s\n",
      "Best parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 16, 'max_features': 'log2', 'max_depth': 100}\n",
      "CV Score: 0.4588169838671222\n",
      "Final Score: 0.5658685864356756\n"
     ]
    }
   ],
   "source": [
    "model, kwargs = tune_random_forest(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.564 ± 0.003\n",
      "CV Average: 0.459 ± 0.013\n",
      "Gap (Train-CV): 0.106\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 29.161 ± 0.162\n",
      "CV Average: 32.482 ± 0.744\n",
      "Gap (CV-Train): 3.322\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 0.275 ± 0.008\n",
      "CV Average: 0.306 ± 0.038\n",
      "Gap (CV-Train): 0.031\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                     Feature  Importance\n",
      "3    mean_batter_runs_scored    0.467138\n",
      "0  mean_batter_runs_conceded    0.293383\n",
      "4      mean_wickets_conceded    0.130179\n",
      "1  mean_extras_runs_conceded    0.064664\n",
      "2         mean_wickets_taken    0.044636\n"
     ]
    }
   ],
   "source": [
    "model, analysis, feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So... There is very little overfitting which is good (likely stemming from the reduced feature set). However scores are marginally worse than our other model with the entire feature set.\n",
    "\n",
    "Based on the fact that we are experiencing very little overfitting, I am going to attempt to increase the model complexity to see if it improves performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 16,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 100}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.641 ± 0.002\n",
      "CV Average: 0.458 ± 0.014\n",
      "Gap (Train-CV): 0.184\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 26.460 ± 0.148\n",
      "CV Average: 32.516 ± 0.761\n",
      "Gap (CV-Train): 6.056\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 0.248 ± 0.008\n",
      "CV Average: 0.304 ± 0.039\n",
      "Gap (CV-Train): 0.056\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                     Feature  Importance\n",
      "3    mean_batter_runs_scored    0.446598\n",
      "0  mean_batter_runs_conceded    0.270235\n",
      "4      mean_wickets_conceded    0.133793\n",
      "1  mean_extras_runs_conceded    0.085035\n",
      "2         mean_wickets_taken    0.064340\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'n_estimators': 1000,\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 8,\n",
    "    'max_features': 'log2',\n",
    "    'max_depth': 50\n",
    "}\n",
    "tuned_model, tuned_analysis, tuned_feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the actaul results stay relatively similar while performance on the training data improves, suggesting that the increase in complexity is only leading to more overfitting.\n",
    "\n",
    "I will therefore use the previous model with the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance:\n",
      "R²: 0.443\n",
      "RMSE: 33.078\n",
      "MAPE: 0.284\n"
     ]
    }
   ],
   "source": [
    "r2, rmse, mape = test_final_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the test scores to those of the random forest model with all features, we see that the scores marginally worse. The R^2 is 0.457 compared to 0.504, RMSE is 33.1 compared to 31.3 and MAPE is 0.296 compared to 0.265.\n",
    "\n",
    "As per my original theory, it is therefore evident that reducing the feature set has not led to an improvement in the random forest model's performance, in fact leading to the opposite. While it does still marginally outperform the baseline model, it is far from ideal.\n",
    "\n",
    "I am curious to see if a more complex model such as a neural network could improve results. If I have time I will try this later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Wicket Estimation\n",
    "\n",
    "Learning from run estimation, I will start by using only total stats. Furthermore I won't bother with feature selection due to the small number of features we'll have.\n",
    "\n",
    "While RFE is useless as above due to the small number of features, I did consider dropping everything except the number of wickets taken/conceded. That being said, in my head it makes sense that either:\n",
    "- More aggressive runs will lead to more wickets being taken\n",
    "- more runs = a better batting side and therefore less wickets conceded\n",
    "\n",
    "I'll evaluate the model results to see if these are the case or if these features were completely insignificant. Hopefully leaving them in shouldn't harm baseline performance much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = [col for col in wicket_estimation_df.columns if 'total' in col[:5]] + ['final_wickets']\n",
    "totals_wicket_estimation_df = wicket_estimation_df[cols_to_keep].copy()\n",
    "\n",
    "cols_to_rename = {\n",
    "    'total_batter_runs_conceded_mean': 'mean_batter_runs_conceded',\n",
    "    'total_runs_from_relevant_extras_mean': 'mean_extras_runs_conceded',\n",
    "    'total_taken_from_relevant_wickets_mean': 'mean_wickets_taken',\n",
    "    'total_runs_batter_mean': 'mean_batter_runs_scored',\n",
    "    'total_is_wicket_mean': 'mean_wickets_conceded'\n",
    "}\n",
    "\n",
    "totals_wicket_estimation_df.rename(columns=cols_to_rename, inplace=True)\n",
    "\n",
    "train_data, test_data = train_test_split(totals_wicket_estimation_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_batter_runs_conceded', 'mean_extras_runs_conceded',\n",
       "       'total_total_runs_conceded_mean', 'mean_wickets_taken',\n",
       "       'mean_batter_runs_scored', 'total_high_scoring_hit_mean',\n",
       "       'total_total_mean', 'mean_wickets_conceded', 'final_wickets'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals_wicket_estimation_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Train R²: 0.439\n",
      "Test R²: 0.439\n",
      "Train RMSE: 2.083\n",
      "Test RMSE: 1.988\n",
      "Train MAPE: 296482630123492.750\n",
      "Test MAPE: 218963026911124.406\n",
      "\n",
      "Feature Coefficients:\n",
      "                          Feature  Coefficient\n",
      "0       mean_batter_runs_conceded     0.360705\n",
      "1       mean_extras_runs_conceded    -0.337859\n",
      "2  total_total_runs_conceded_mean    -0.263096\n",
      "3              mean_wickets_taken     0.454511\n",
      "4         mean_batter_runs_scored    -1.042803\n",
      "5     total_high_scoring_hit_mean    -2.386746\n",
      "6                total_total_mean     2.919206\n",
      "7           mean_wickets_conceded     1.416949\n"
     ]
    }
   ],
   "source": [
    "model, metrics, coefficients = train_and_evaluate_baseline_model(train_data, test_data, 'final_wickets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(6.32298755186722)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totals_wicket_estimation_df['final_wickets'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay interesting. The model is okay, but not amazing.\n",
    "\n",
    "The absurd MAPE values are liekly due to games with 0 wickets conceded as I know that MAPE struggles with 0 values.\n",
    "\n",
    "THat being said, the result of only 2 wickets taken off is okay. Based on the mean value of 6.30 wickets conceded per game, this suggests that the actual MAPE is again around 0.3 which is not terrible but again really not great.\n",
    "\n",
    "Similar results for R^2 compared to run estimation, hence similar conclusions.\n",
    "\n",
    "It is however interesting that the model does not find mean_wickets_taken very important. I want to repeat this one more time with only wickets taken statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Train R²: 0.373\n",
      "Test R²: 0.373\n",
      "Train RMSE: 2.204\n",
      "Test RMSE: 2.128\n",
      "Train MAPE: 346457614875782.062\n",
      "Test MAPE: 255628949893465.969\n",
      "\n",
      "Feature Coefficients:\n",
      "                 Feature  Coefficient\n",
      "0     mean_wickets_taken     0.500921\n",
      "1  mean_wickets_conceded     1.514715\n"
     ]
    }
   ],
   "source": [
    "wickets_only = totals_wicket_estimation_df[['mean_wickets_taken', 'mean_wickets_conceded', 'final_wickets']]\n",
    "\n",
    "train_data, test_data = train_test_split(wickets_only, test_size=0.2, random_state=42)\n",
    "\n",
    "model, metrics, coefficients = train_and_evaluate_baseline_model(train_data, test_data, 'final_wickets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly this performs even worse, and mean_wickets_taken is not much more important than when all of the other features were included.\n",
    "\n",
    "This suggests they may indeed be of somewhat importance to predicting the number of wickets taken."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest for Wicket Estimation\n",
    "\n",
    "I will now repeat the same process for wicket estimation as I did for run estimation.\n",
    "Based on my results above with the baseline and also those of the random forest with all features, I will start with all features. I may attempt to slim down the feature set later, however my experiments on run estimation suggest that this will not lead to any meaningful improvements and would probably be a waste of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wicket_estimation_df\n",
    "X = data.drop(columns=['final_wickets'])\n",
    "y = data['final_wickets']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.931 ± 0.002\n",
      "CV Average: 0.510 ± 0.048\n",
      "Gap (Train-CV): 0.421\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 0.729 ± 0.009\n",
      "CV Average: 1.943 ± 0.075\n",
      "Gap (CV-Train): 1.214\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 94192542934474.469 ± 5166293985991.008\n",
      "CV Average: 253152973135584.312 ± 29277357519708.965\n",
      "Gap (CV-Train): 158960430201109.844\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                                           Feature  Importance\n",
      "15                            total_is_wicket_mean    0.446536\n",
      "3           total_taken_from_relevant_wickets_mean    0.056654\n",
      "19                        powerplay_is_wicket_mean    0.049234\n",
      "11  non_powerplay_taken_from_relevant_wickets_mean    0.047735\n",
      "23                    non_powerplay_is_wicket_mean    0.047499\n",
      "13                     total_high_scoring_hit_mean    0.033176\n",
      "7       powerplay_taken_from_relevant_wickets_mean    0.026767\n",
      "5         powerplay_runs_from_relevant_extras_mean    0.024932\n",
      "1             total_runs_from_relevant_extras_mean    0.023517\n",
      "9     non_powerplay_runs_from_relevant_extras_mean    0.022822\n"
     ]
    }
   ],
   "source": [
    "model, analysis, feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to out baseline, we see at least a marginally better model performance across the board. The model is able to fit the data better, as evidenced by the greater R^2 values, as well as having a slightly lower RMSE. Again due to the presence of 0 values, the MAPE is pretty useless here.\n",
    "\n",
    "There is however clear evidence of overfitting, as evidenced by the somewhat high CV gap for both R^2 and RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=500; total time=   5.6s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=8, min_samples_split=5, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=  13.7s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=  13.9s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=  14.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=500; total time=   5.7s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=20, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=20, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=20, n_estimators=300; total time=   3.7s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=20, n_estimators=300; total time=   3.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=100; total time=   1.0s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, max_features=log2, min_samples_leaf=8, min_samples_split=10, n_estimators=500; total time=   5.8s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=50, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=50, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=50, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=50, max_features=log2, min_samples_leaf=4, min_samples_split=20, n_estimators=300; total time=   3.5s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=50, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=4, min_samples_split=50, n_estimators=100; total time=   1.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=8, min_samples_split=50, n_estimators=300; total time=   3.1s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=200; total time=  11.9s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=200; total time=  12.1s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=200; total time=  12.3s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=200; total time=  11.8s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=8, min_samples_split=5, n_estimators=200; total time=  12.3s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  21.5s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  21.9s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  22.5s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.7s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=300; total time=  18.7s\n",
      "Best parameters: {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 50}\n",
      "CV Score: 0.5144846900286966\n",
      "Final Score: 0.9176103994388383\n"
     ]
    }
   ],
   "source": [
    "model, kwargs = tune_random_forest(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.916 ± 0.003\n",
      "CV Average: 0.514 ± 0.047\n",
      "Gap (Train-CV): 0.402\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 0.806 ± 0.010\n",
      "CV Average: 1.934 ± 0.073\n",
      "Gap (CV-Train): 1.129\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 111323872801157.031 ± 4633725188239.227\n",
      "CV Average: 254275595828873.312 ± 30329714765770.172\n",
      "Gap (CV-Train): 142951723027716.281\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                                           Feature  Importance\n",
      "15                            total_is_wicket_mean    0.456886\n",
      "3           total_taken_from_relevant_wickets_mean    0.055818\n",
      "19                        powerplay_is_wicket_mean    0.049334\n",
      "11  non_powerplay_taken_from_relevant_wickets_mean    0.048233\n",
      "23                    non_powerplay_is_wicket_mean    0.047270\n",
      "13                     total_high_scoring_hit_mean    0.031911\n",
      "7       powerplay_taken_from_relevant_wickets_mean    0.025743\n",
      "5         powerplay_runs_from_relevant_extras_mean    0.024840\n",
      "1             total_runs_from_relevant_extras_mean    0.023601\n",
      "9     non_powerplay_runs_from_relevant_extras_mean    0.022513\n"
     ]
    }
   ],
   "source": [
    "model, analysis, feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the model is overfitting less, the scores have not improved whatsoever. We still see the same CV R^2 and RMSE, suggesting that perhaps the model is a) not a good fit for the data or b) the model has reached the capacity of how much it can learn from the data.\n",
    "\n",
    "Since the model has not capped out at any of the hyperparameters (on an end of either complexity or reducing overfitting), this suggets that it further hyperparameter tuning will be unlikely to improve performance significantly.\n",
    "\n",
    "Despite this, it is a 5-10 percent improvement in RMSE over the baseline model, so it is not nothing, though not significant. I will evaluate the final performance of the model with the test set and see how it compares.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance:\n",
      "R²: 0.560\n",
      "RMSE: 1.816\n",
      "MAPE: 178390577160366.719\n"
     ]
    }
   ],
   "source": [
    "r2, rmse, mape = test_final_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/match_models/wicket_model.joblib']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, '../models/match_models/wicket_model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results here are very similar to those of the validation set. It does suggest minimal overfitting for the model, however again the scores are not a great improvement over the baseline model.\n",
    "\n",
    "While I do not expect much or any of an improvement, I will repeat this with only the total features to see if I am wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = totals_wicket_estimation_df\n",
    "X = data.drop(columns=['final_wickets'])\n",
    "y = data['final_wickets']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.925 ± 0.002\n",
      "CV Average: 0.461 ± 0.050\n",
      "Gap (Train-CV): 0.464\n",
      "CV Consistency: Unstable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 0.761 ± 0.009\n",
      "CV Average: 2.039 ± 0.073\n",
      "Gap (CV-Train): 1.277\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 97283759358546.141 ± 5209345242949.933\n",
      "CV Average: 253691937645106.094 ± 39418892437442.836\n",
      "Gap (CV-Train): 156408178286559.938\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                          Feature  Importance\n",
      "7           mean_wickets_conceded    0.491560\n",
      "3              mean_wickets_taken    0.123204\n",
      "5     total_high_scoring_hit_mean    0.100704\n",
      "1       mean_extras_runs_conceded    0.081088\n",
      "0       mean_batter_runs_conceded    0.051725\n",
      "2  total_total_runs_conceded_mean    0.051554\n",
      "4         mean_batter_runs_scored    0.051499\n",
      "6                total_total_mean    0.048667\n"
     ]
    }
   ],
   "source": [
    "# No Hyperparameter tuning:\n",
    "model, analysis, feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  11.9s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  11.9s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  12.0s\n",
      "[CV] END max_depth=100, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  12.3s\n",
      "[CV] END max_depth=100, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  12.4s\n",
      "[CV] END max_depth=100, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  12.4s\n",
      "[CV] END max_depth=100, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  12.5s\n",
      "[CV] END max_depth=100, max_features=None, min_samples_leaf=2, min_samples_split=10, n_estimators=500; total time=  12.6s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.4s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.2s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.5s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=500; total time=   4.5s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=20, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.1s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.3s\n",
      "[CV] END max_depth=10, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=   1.2s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=100; total time=   1.9s\n",
      "[CV] END max_depth=10, max_features=None, min_samples_leaf=2, min_samples_split=50, n_estimators=100; total time=   1.8s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.2s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   2.3s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  11.7s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=500; total time=   3.0s\n",
      "[CV] END max_depth=50, max_features=None, min_samples_leaf=4, min_samples_split=5, n_estimators=500; total time=  12.1s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=50, max_features=sqrt, min_samples_leaf=16, min_samples_split=10, n_estimators=100; total time=   0.6s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=500; total time=   2.8s\n",
      "[CV] END max_depth=20, max_features=sqrt, min_samples_leaf=16, min_samples_split=2, n_estimators=500; total time=   2.9s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   6.1s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   6.2s\n",
      "[CV] END max_depth=20, max_features=None, min_samples_leaf=16, min_samples_split=10, n_estimators=400; total time=   6.1s\n",
      "Best parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "CV Score: 0.483799558762313\n",
      "Final Score: 0.7898878261025459\n"
     ]
    }
   ],
   "source": [
    "model, kwargs = tune_random_forest(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Analysis:\n",
      "\n",
      "R² Scores:\n",
      "Training Average: 0.789 ± 0.005\n",
      "CV Average: 0.484 ± 0.046\n",
      "Gap (Train-CV): 0.305\n",
      "CV Consistency: Stable\n",
      "\n",
      "RMSE Scores:\n",
      "Training Average: 1.278 ± 0.011\n",
      "CV Average: 1.995 ± 0.066\n",
      "Gap (CV-Train): 0.717\n",
      "\n",
      "MAPE Scores:\n",
      "Training Average: 185879094819999.875 ± 6600367833445.821\n",
      "CV Average: 278097212303978.406 ± 34934462933705.086\n",
      "Gap (CV-Train): 92218117483978.531\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                          Feature  Importance\n",
      "7           mean_wickets_conceded    0.415649\n",
      "3              mean_wickets_taken    0.131446\n",
      "5     total_high_scoring_hit_mean    0.117771\n",
      "6                total_total_mean    0.077023\n",
      "4         mean_batter_runs_scored    0.072836\n",
      "1       mean_extras_runs_conceded    0.069087\n",
      "2  total_total_runs_conceded_mean    0.058419\n",
      "0       mean_batter_runs_conceded    0.057769\n"
     ]
    }
   ],
   "source": [
    "model, analysis, feature_importance = do_random_forest(X_train, y_train, cv=5, random_state=42, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, the hyperparameter tuning does lead to more of an improvement here than while using all features. That being said, it still performs worse than said model (albeit marginally better than the baseline). I expect altering model complexity to again have very limited impact based on all of the results up to this point, hence I do not expect to gain anything from trying it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Performance:\n",
      "R²: 0.515\n",
      "RMSE: 1.908\n",
      "MAPE: 200142408852437.250\n"
     ]
    }
   ],
   "source": [
    "r2, rmse, mape = test_final_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen with the cross validation results, the model does not outperform the similar one with a full feature set, albeit it does marginally better than the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_results(data, run_model, wicket_model):\n",
    "    X = data.drop(columns=['game_id', 'innings', 'final_runs', 'final_wickets'])\n",
    "    y_wicket = data['final_wickets']\n",
    "    y_run = data['final_runs']\n",
    "\n",
    "    run_pred = run_model.predict(X)\n",
    "    wicket_pred = wicket_model.predict(X)\n",
    "    \n",
    "    r2_run = r2_score(y_run, run_pred)\n",
    "    rmse_run = np.sqrt(mean_squared_error(y_run, run_pred))\n",
    "    mape_run = mean_absolute_percentage_error(y_run, run_pred)\n",
    "    \n",
    "    r2_wicket = r2_score(y_wicket, wicket_pred)\n",
    "    rmse_wicket = np.sqrt(mean_squared_error(y_wicket, wicket_pred))\n",
    "    mape_wicket = mean_absolute_percentage_error(y_wicket, wicket_pred)\n",
    "\n",
    "    final_results = np.column_stack((run_pred, wicket_pred))\n",
    "\n",
    "    print(f\"R^2 Run: {r2_run:.3f}, RMSE Run: {rmse_run:.3f}, MAPE Run: {mape_run:.3f}\")\n",
    "    print(f\"R^2 Wicket: {r2_wicket:.3f}, RMSE Wicket: {rmse_wicket:.3f}, MAPE Wicket: {mape_wicket:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'final_results': final_results,\n",
    "        'r2_run': r2_run,\n",
    "        'rmse_run': rmse_run,\n",
    "        'mape_run': mape_run,\n",
    "        'r2_wicket': r2_wicket,\n",
    "        'rmse_wicket': rmse_wicket,\n",
    "        'mape_wicket': mape_wicket\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Run: 0.452, RMSE Run: 34.097, MAPE Run: 0.407\n",
      "R^2 Wicket: 0.550, RMSE Wicket: 1.962, MAPE Wicket: 423238373516824.688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[127.80650631,   2.41243519],\n",
       "       [121.76272114,   7.18928956],\n",
       "       [107.42967857,   7.26761917],\n",
       "       ...,\n",
       "       [102.97829969,   4.03808057],\n",
       "       [ 84.90747863,   8.36710053],\n",
       "       [101.88337698,   5.71592155]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('../data/saved_data/match_test_data.csv')\n",
    "run_model = load('../models/match_models/run_model.joblib')\n",
    "wicket_model = load('../models/match_models/wicket_model.joblib')\n",
    "results = calculate_results(test_data, run_model, wicket_model)\n",
    "results['final_results']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding-task-BR_zkfTV-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
