{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import collections, operator, functools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_ball_data = pd.read_csv('../data/saved_data/all_matches.csv')\n",
    "per_ball_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_ball_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Per player statistics: Bowlers\n",
    "\n",
    "We want to rate the bowlers based on their performances.\n",
    "On average:\n",
    "- How many wickets does each bowler take per ball?\n",
    "- How many runs does each bowler give up per ball?\n",
    "- How many bowler-related extras does each bowler give up per ball?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_ball_data['wicket_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll need to parse extras details as a string so we can analyse them better.\n",
    "def parse_extras_details(extras_details):\n",
    "    if pd.isna(extras_details):\n",
    "        return {}\n",
    "    try:\n",
    "        return ast.literal_eval(extras_details)\n",
    "    except:\n",
    "        return {}\n",
    "per_ball_data['extras_details'] = per_ball_data['extras_details'].apply(parse_extras_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_ball_data['extras_details'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extras_details = per_ball_data[per_ball_data['extras_details'] != {}]['extras_details']\n",
    "\n",
    "def sum_dict_series(series):\n",
    "    # Apply Counter to each dictionary and reduce\n",
    "    result = dict(functools.reduce(operator.add,\n",
    "                                 map(collections.Counter, series)))\n",
    "    return result\n",
    "\n",
    "extras_counts = sum_dict_series(extras_details)\n",
    "extras_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicts_to_add = [{'a': 1, 'b': 2}, {'a': 3, 'c': 4}]\n",
    "total_counts = {}\n",
    "for extras_dict in dicts_to_add:\n",
    "    total_counts = {**total_counts, **extras_dict}\n",
    "total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowlers_df = per_ball_data[['game_id', 'bowler', 'runs_batter', 'extras', 'total', 'is_wicket', 'wicket_type', 'extras_details', 'powerplay']].copy()\n",
    "bowlers_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bowler_statistics(per_ball_data):\n",
    "    bowlers_df = per_ball_data[['game_id', 'bowler', 'runs_batter', 'extras', 'total', 'is_wicket', 'wicket_type', 'extras_details', 'powerplay']].copy()\n",
    "    relevant_wicket_types = ['bowled', 'lbw', 'caught', 'caught and bowled', 'stumped']\n",
    "    bowlers_df['relevant_wicket'] = bowlers_df['wicket_type'].isin(relevant_wicket_types)\n",
    "    relevant_extras_types = ['noballs', 'wides']\n",
    "    bowlers_df['runs_from_relevant_extras'] = bowlers_df['extras_details'].apply(lambda x: sum(x.get(key, 0) for key in relevant_extras_types))\n",
    "    \n",
    "    powerplay_df = bowlers_df[bowlers_df['powerplay'] == True]\n",
    "    non_powerplay_df = bowlers_df[bowlers_df['powerplay'] == False]\n",
    "\n",
    "    total_stats = bowlers_df.groupby('bowler').agg({\n",
    "        'runs_batter': ['mean'],\n",
    "        'runs_from_relevant_extras': ['mean'],\n",
    "        'total': ['mean'],\n",
    "        'relevant_wicket': ['mean']\n",
    "    }).rename(columns={'runs_batter': 'batter_runs_conceded', 'total': 'total_runs_conceded', 'relevant_wicket': 'taken_from_relevant_wickets'})\n",
    "\n",
    "    powerplay_stats = powerplay_df.groupby('bowler').agg({\n",
    "        'runs_batter': ['mean'],\n",
    "        'runs_from_relevant_extras': ['mean'],\n",
    "        'total': ['mean'],\n",
    "        'relevant_wicket': ['mean']\n",
    "    }).rename(columns={'runs_batter': 'batter_runs_conceded', 'total': 'total_runs_conceded', 'relevant_wicket': 'taken_from_relevant_wickets'})\n",
    "\n",
    "    non_powerplay_stats = non_powerplay_df.groupby('bowler').agg({\n",
    "        'runs_batter': ['mean'],\n",
    "        'runs_from_relevant_extras': ['mean'],\n",
    "        'total': ['mean'],\n",
    "        'relevant_wicket': ['mean']\n",
    "    }).rename(columns={'runs_batter': 'batter_runs_conceded', 'total': 'total_runs_conceded', 'relevant_wicket': 'taken_from_relevant_wickets'}) \n",
    "\n",
    "    total_stats.columns = [\n",
    "        f'total_{col[0]}_{col[1]}' for col in total_stats.columns\n",
    "    ]\n",
    "    powerplay_stats.columns = [\n",
    "        f'powerplay_{col[0]}_{col[1]}' for col in powerplay_stats.columns\n",
    "    ]\n",
    "    non_powerplay_stats.columns = [\n",
    "        f'non_powerplay_{col[0]}_{col[1]}' for col in non_powerplay_stats.columns\n",
    "    ]\n",
    "\n",
    "    bowler_stats = pd.concat([\n",
    "        total_stats,\n",
    "        powerplay_stats,\n",
    "        non_powerplay_stats\n",
    "    ], axis=1)\n",
    "    return bowler_stats\n",
    "bowler_stats = get_bowler_statistics(per_ball_data)\n",
    "bowler_stats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bowler_stats.reset_index().to_csv('../data/saved_data/bowler_stats.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Per player statistics: Batsmen\n",
    "\n",
    "We want to rate the batsmen based on their performances.\n",
    "On average:\n",
    "- How many runs do they score per ball?\n",
    "- How many high-scoring hits do they make per ball (4 or more runs)? (using as don't have boundaries data)\n",
    "    - For runs/high-scoring hits, we'll separate powerplay, and non-powerplay, as well as total.\n",
    "- How often are they gotten out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batsmen_df = per_ball_data[['game_id', 'batter', 'runs_batter', 'extras', 'total', 'is_wicket', 'powerplay']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batsman_statistics(per_ball_data):\n",
    "    batsmen_df = per_ball_data[['game_id', 'batter', 'runs_batter', 'extras', 'total', 'is_wicket', 'powerplay']].copy()\n",
    "    batsmen_df['high_scoring_hit'] = batsmen_df['runs_batter'] >= 4\n",
    "\n",
    "    powerplay_df = batsmen_df[batsmen_df['powerplay'] == True]\n",
    "    non_powerplay_df = batsmen_df[batsmen_df['powerplay'] == False]\n",
    "\n",
    "    total_stats = batsmen_df.groupby('batter').agg({\n",
    "        'runs_batter': ['mean'],\n",
    "        'high_scoring_hit': ['mean'],\n",
    "        'total': ['mean'],\n",
    "        'is_wicket': ['mean']\n",
    "    })\n",
    "\n",
    "    powerplay_stats = powerplay_df.groupby('batter').agg({\n",
    "        'runs_batter': ['mean'],\n",
    "        'high_scoring_hit': ['mean'],\n",
    "        'total': ['mean'],\n",
    "        'is_wicket': ['mean']\n",
    "    })\n",
    "\n",
    "    non_powerplay_stats = non_powerplay_df.groupby('batter').agg({\n",
    "        'runs_batter': ['mean'],\n",
    "        'high_scoring_hit': ['mean'],\n",
    "        'total': ['mean'],\n",
    "        'is_wicket': ['mean']\n",
    "    })\n",
    "\n",
    "    total_stats.columns = [\n",
    "        f'total_{col[0]}_{col[1]}' for col in total_stats.columns\n",
    "    ]\n",
    "    powerplay_stats.columns = [\n",
    "        f'powerplay_{col[0]}_{col[1]}' for col in powerplay_stats.columns\n",
    "    ]\n",
    "    non_powerplay_stats.columns = [\n",
    "        f'non_powerplay_{col[0]}_{col[1]}' for col in non_powerplay_stats.columns\n",
    "    ]\n",
    "\n",
    "    batsman_stats = pd.concat([\n",
    "        total_stats,\n",
    "        powerplay_stats,\n",
    "        non_powerplay_stats\n",
    "    ], axis=1)\n",
    "\n",
    "    return batsman_stats\n",
    "batsman_stats = get_batsman_statistics(per_ball_data)\n",
    "batsman_stats.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batsman_stats.reset_index().to_csv('../data/saved_data/batter_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some nan values in the stats. This should be all good though, it suggests that they have not batted in powerplays etc...\n",
    "Will keep as is, they shouldn't be counted in the per-team stats and therefore we don't want to replace with 0.\n",
    "\n",
    "Now for merging back onto the original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_game_data = per_ball_data[['game_id', 'innings', 'bowler', 'batter', 'current_runs', 'current_wickets']].copy()\n",
    "per_game_data = per_game_data.merge(bowler_stats, on=['bowler'], how='left') \\\n",
    "                             .merge(batsman_stats, on=['batter'], how='left')\n",
    "per_game_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_game_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_game_aggregated = per_game_data.groupby(['game_id', 'innings']).agg({ # will effectively calculate weighted averages of bowler and batsman stats depending on no. of balls\n",
    "    **{column: 'mean' for column in per_game_data.columns if column not in ['game_id', 'innings', 'bowler', 'batter', 'current_runs', 'current_wickets']},\n",
    "    'current_runs': 'max',\n",
    "    'current_wickets': 'max'\n",
    "}).rename(columns={'current_runs': 'final_runs', 'current_wickets': 'final_wickets'})\n",
    "per_game_aggregated.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_game_aggregated.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all columns to have mean 0 and standard deviation 1\n",
    "standardized = (per_game_aggregated - per_game_aggregated.mean()) / per_game_aggregated.std()\n",
    "standardized = standardized.drop(columns=['final_runs', 'final_wickets']).merge(per_game_aggregated.reset_index()[['game_id', 'innings', 'final_runs', 'final_wickets']], on=['game_id', 'innings'], how='left')\n",
    "standardized.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.to_csv('../data/saved_data/standardized_per_game_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Possibly a glaring issue:\n",
    "So I woke up this morning and realised one key thing. Each player is being rated on their performances over their entire career, not just up until the current game. \n",
    "\n",
    "I don't know how big an issue this is, but it's definitely notable - if it is a player's first game, they're being rated on their t20 career past that point. I belive this issue is known as 'data leakage', and I should probably instead look at player's games up to the current game instead of for their entire career, especially since the dataset spans several decades.\n",
    "\n",
    "I think that even if it hurts the performance of the model, it's a more accurate representation of the players' abilities and therefore a better way to do predictions - it would allow us to predict games better in the future as well.\n",
    "\n",
    "In order to implement this:\n",
    "1. Get players' match data up to the current game\n",
    "2. Use relevant number of games and use that to calculate stats\n",
    "3. Otherwise same as before.\n",
    "\n",
    "Impl:\n",
    "- Groupby player and within that group by game.\n",
    "- Calculate per_game stats for the player - easy using groupby and aggregate operations similar to above.\n",
    "- Use a rolling window with the end being the current game and the size being the number of balls/games in order to calculate stats\n",
    "    - May be more more challenging as window size may spill onto different players, but should be fine to work around.\n",
    "    - This should hopefully be somewhat efficient using the windowed approach compared to lookup tables or going row by row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Trend analysis\n",
    "\n",
    "Before I commit to the above, I'm going to inspect how players' stats change over time. The caveat to the above is that (from my limited knowledge of cricket) players usually only play for in t20 internationals for a few years during their primes, so this may not be a big issue.\n",
    "\n",
    "If the general trend is that players' stats change very little over time, then I don't think it's a big issue using all of a player's data rather than just their data up to the current game, as the stats are unlikely to change much. Furthermore it's also significantly more efficient an implementation than needing to calculate previous games.\n",
    "\n",
    "If however players' stats change a lot over time, then I should probably use historical data only.\n",
    "\n",
    "For the sake of time, I am only going to look at batter runs and wickets taken. These are probably the most important stats and should give a good indication of what I need to know.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After suggestions from a friend who works in Biomedical research and then further independent research online, I've decided to use CUSUM analysis to detect changes in players' stats over time.\n",
    "\n",
    "While I understand the theory behind it, I've never implemented it before, so copilot did a lot of the heavy lifting here. I can't really credit myself for the following implementation, all I did was adapt the code it generated to fit my data and needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_cusum_analysis(df, player_id, metric='runs_batter', threshold=1, check = 'bowler'):\n",
    "    # Get player's chronological data\n",
    "    player_data = df[df[check] == player_id] \\\n",
    "                            .sort_values(by='date', ascending=True)[['game_id', metric]] \\\n",
    "                            .groupby('game_id').agg('mean') \\\n",
    "                            .values \\\n",
    "                            .flatten()\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = np.mean(player_data)\n",
    "    std = np.std(player_data)\n",
    "    \n",
    "    # Initialize CUSUM arrays\n",
    "    cusum_pos = np.zeros(len(player_data))\n",
    "    cusum_neg = np.zeros(len(player_data))\n",
    "    \n",
    "    # Calculate CUSUM values\n",
    "    for i in range(1, len(player_data)):\n",
    "        # Standardize the observation\n",
    "        z_score = (player_data[i] - mean) / std\n",
    "        \n",
    "        # Calculate positive and negative CUSUMs\n",
    "        cusum_pos[i] = max(0, float(cusum_pos[i-1] + z_score - threshold))\n",
    "        cusum_neg[i] = min(0, float(cusum_neg[i-1] + z_score + threshold))\n",
    "    \n",
    "    # Detect change points\n",
    "    change_points = np.where(\n",
    "        (abs(cusum_pos) > threshold) | \n",
    "        (abs(cusum_neg) > threshold)\n",
    "    )[0]\n",
    "    \n",
    "    return {\n",
    "        'cusum_pos': cusum_pos,\n",
    "        'cusum_neg': cusum_neg,\n",
    "        'change_points': change_points,\n",
    "        'mean': mean,\n",
    "        'std': std\n",
    "    }\n",
    "\n",
    "def analyze_performance_stability(df, metrics=['runs_batter', 'is_wicket'], check = 'bowler'):\n",
    "    def categorize_trend(cusum_result):\n",
    "        # If no significant changes, performance is stable\n",
    "        if len(cusum_result['change_points']) == 0:\n",
    "            return 'stable'\n",
    "        \n",
    "        # Look at direction of changes\n",
    "        pos_changes = cusum_result['cusum_pos'].max() > 1\n",
    "        neg_changes = cusum_result['cusum_neg'].min() < -1\n",
    "        \n",
    "        if pos_changes and neg_changes:\n",
    "            return 'variable'  # Both improvement and decline\n",
    "        elif pos_changes:\n",
    "            return 'improving'\n",
    "        elif neg_changes:\n",
    "            return 'declining'\n",
    "        return 'stable'\n",
    "    \n",
    "    results = {}\n",
    "    for player in tqdm(df['bowler'].unique()):\n",
    "        player_trends = {}\n",
    "        for metric in metrics:\n",
    "            cusum_result = perform_cusum_analysis(df, player, metric)\n",
    "            player_trends[metric] = categorize_trend(cusum_result)\n",
    "        results[player] = player_trends\n",
    "    \n",
    "    # Summarize results\n",
    "    summary = {metric: {} for metric in metrics}\n",
    "    for metric in tqdm(metrics):\n",
    "        trends = [results[player][metric] for player in results]\n",
    "        summary[metric] = {\n",
    "            'stable': trends.count('stable') / len(trends),\n",
    "            'improving': trends.count('improving') / len(trends),\n",
    "            'declining': trends.count('declining') / len(trends),\n",
    "            'variable': trends.count('variable') / len(trends)\n",
    "        }\n",
    "    \n",
    "    return results, summary\n",
    "\n",
    "# Run analysis\n",
    "player_trends, trend_summary = analyze_performance_stability(per_ball_data, check='bowler')\n",
    "\n",
    "# Print summary\n",
    "print(\"Performance Stability Analysis: Bowlers\")\n",
    "for metric, stats in trend_summary.items():\n",
    "    print(f\"{metric}:\")\n",
    "    for trend, proportion in stats.items():\n",
    "        print(f\"{trend}: {proportion:.1%}\")\n",
    "    print('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_trends, trend_summary = analyze_performance_stability(per_ball_data, check='batter')\n",
    "\n",
    "# Print summary\n",
    "print(\"Performance Stability Analysis: Batsmen\")\n",
    "for metric, stats in trend_summary.items():\n",
    "    print(f\"{metric}:\")\n",
    "    for trend, proportion in stats.items():\n",
    "        print(f\"{trend}: {proportion:.1%}\")\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cusum_analysis(df, player_id, metric='runs_batter', threshold=1):\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    result = perform_cusum_analysis(df, player_id, metric, threshold)\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "\n",
    "        # Get player's chronological data\n",
    "    player_data = df[df['bowler'] == player_id] \\\n",
    "                            .sort_values(by='date', ascending=True)[['game_id', metric]] \\\n",
    "                            .groupby('game_id').agg('mean') \\\n",
    "                            .values \\\n",
    "                            .flatten()\n",
    "    # Plot 1: Raw performance data\n",
    "    ax1.plot(player_data, 'b-', label='Performance')\n",
    "    ax1.axhline(y=result['mean'], color='r', linestyle='--', label='Mean')\n",
    "    ax1.axhline(y=result['mean'] + result['std'], color='g', linestyle=':', label='+1 SD')\n",
    "    ax1.axhline(y=result['mean'] - result['std'], color='g', linestyle=':', label='-1 SD')\n",
    "    ax1.set_title(f'Raw Performance Data{\" for \" + player_id if player_id else \"\"}')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: CUSUM chart\n",
    "    ax2.plot(result['cusum_pos'], 'g-', label='Positive CUSUM')\n",
    "    ax2.plot(result['cusum_neg'], 'r-', label='Negative CUSUM')\n",
    "    ax2.axhline(y=0, color='b', linestyle='--')\n",
    "    \n",
    "    # Highlight change points\n",
    "    for cp in result['change_points']:\n",
    "        ax2.axvline(x=cp, color='purple', alpha=0.3)\n",
    "    \n",
    "    ax2.set_title('CUSUM Analysis')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Mean performance: {result['mean']:.2f}\")\n",
    "    print(f\"Standard deviation: {result['std']:.2f}\")\n",
    "    print(f\"Number of change points: {len(result['change_points'])}\")\n",
    "    if len(result['change_points']) > 0:\n",
    "        print(f\"Change points at games: {result['change_points'].tolist()}\")\n",
    "\n",
    "\n",
    "visualize_cusum_analysis(per_ball_data, '3a60e0b5', 'runs_batter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these results it seems that over 2/3 of players have no significant changes in their performances over time. Furthermore, since CUSUM analysis only tracks when there is repeated improvement or decline, we can be fairly confident that blips in form of 1-2 games do not significantly affect results. Furthermore, my relatively low (arbitrarily chosen) threshold of 1sd away from the mean is fairly conservative, so there's a good chance that my results will be overestimating players' changes in form over time...\n",
    "\n",
    "Therefore, I am going to keep my current approach of using all of a player's data in the dataset to predict results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding-task-BR_zkfTV-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
