{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling the sequence of a cricket game\n",
    "\n",
    "Seperately from the previous modeling, where I tried to predict the outcome of a game based on the stats of the players, I want to attempt to model a cricket game itself, ball by ball.\n",
    "\n",
    "I will create three models:\n",
    "1. A model that predicts the probability of a wicket occuring in a ball.\n",
    "2. A model predicting the number of extras resulting from a ball.\n",
    "3. A model predicting the number of runs scored by a ball.\n",
    "\n",
    "These will then be combined into a finite state machine with the aim of predicting the outcome of the game through modelling the sequence of events within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Predicting the probability of a wicket occuring in a ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 857199 entries, 0 to 857198\n",
      "Data columns (total 29 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   game_id               857199 non-null  object \n",
      " 1   date                  857199 non-null  object \n",
      " 2   venue                 857199 non-null  object \n",
      " 3   location              816895 non-null  object \n",
      " 4   gender                857199 non-null  object \n",
      " 5   match_type            857199 non-null  object \n",
      " 6   innings               857199 non-null  int64  \n",
      " 7   batting_team          857199 non-null  object \n",
      " 8   bowling_team          857199 non-null  object \n",
      " 9   batting_team_players  857199 non-null  object \n",
      " 10  bowling_team_players  857199 non-null  object \n",
      " 11  over                  857199 non-null  int64  \n",
      " 12  ball_in_over          857199 non-null  int64  \n",
      " 13  batter                857199 non-null  object \n",
      " 14  bowler                857199 non-null  object \n",
      " 15  non_striker           857199 non-null  object \n",
      " 16  runs_batter           857199 non-null  int64  \n",
      " 17  extras                857199 non-null  int64  \n",
      " 18  total                 857199 non-null  int64  \n",
      " 19  is_wicket             857199 non-null  bool   \n",
      " 20  wicket_type           47416 non-null   object \n",
      " 21  fielder               29853 non-null   object \n",
      " 22  player_out            47416 non-null   object \n",
      " 23  target_runs           392608 non-null  float64\n",
      " 24  target_overs          392608 non-null  float64\n",
      " 25  current_runs          857199 non-null  int64  \n",
      " 26  current_wickets       857199 non-null  int64  \n",
      " 27  powerplay             857199 non-null  bool   \n",
      " 28  extras_details        55337 non-null   object \n",
      "dtypes: bool(2), float64(2), int64(8), object(17)\n",
      "memory usage: 178.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/saved_data/all_matches.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batter_stats = pd.read_csv('../data/saved_data/batter_stats.csv')\n",
    "bowler_stats = pd.read_csv('../data/saved_data/bowler_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batter</th>\n",
       "      <th>total_runs_batter_mean</th>\n",
       "      <th>total_high_scoring_hit_mean</th>\n",
       "      <th>total_total_mean</th>\n",
       "      <th>total_is_wicket_mean</th>\n",
       "      <th>powerplay_runs_batter_mean</th>\n",
       "      <th>powerplay_high_scoring_hit_mean</th>\n",
       "      <th>powerplay_total_mean</th>\n",
       "      <th>powerplay_is_wicket_mean</th>\n",
       "      <th>non_powerplay_runs_batter_mean</th>\n",
       "      <th>non_powerplay_high_scoring_hit_mean</th>\n",
       "      <th>non_powerplay_total_mean</th>\n",
       "      <th>non_powerplay_is_wicket_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00015688</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00029c30</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a57d</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00321fff</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.673469</td>\n",
       "      <td>0.081633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00467a76</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>1.088608</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>1.088608</td>\n",
       "      <td>0.101266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batter  total_runs_batter_mean  total_high_scoring_hit_mean  \\\n",
       "0  00015688                0.294118                     0.029412   \n",
       "1  00029c30                0.454545                     0.000000   \n",
       "2  0030a57d                0.533333                     0.000000   \n",
       "3  00321fff                0.612245                     0.040816   \n",
       "4  00467a76                0.974684                     0.101266   \n",
       "\n",
       "   total_total_mean  total_is_wicket_mean  powerplay_runs_batter_mean  \\\n",
       "0          0.485294              0.044118                       0.375   \n",
       "1          0.818182              0.000000                         NaN   \n",
       "2          0.733333              0.000000                         NaN   \n",
       "3          0.673469              0.081633                         NaN   \n",
       "4          1.088608              0.101266                         NaN   \n",
       "\n",
       "   powerplay_high_scoring_hit_mean  powerplay_total_mean  \\\n",
       "0                             0.05                 0.525   \n",
       "1                              NaN                   NaN   \n",
       "2                              NaN                   NaN   \n",
       "3                              NaN                   NaN   \n",
       "4                              NaN                   NaN   \n",
       "\n",
       "   powerplay_is_wicket_mean  non_powerplay_runs_batter_mean  \\\n",
       "0                     0.025                        0.178571   \n",
       "1                       NaN                        0.454545   \n",
       "2                       NaN                        0.533333   \n",
       "3                       NaN                        0.612245   \n",
       "4                       NaN                        0.974684   \n",
       "\n",
       "   non_powerplay_high_scoring_hit_mean  non_powerplay_total_mean  \\\n",
       "0                             0.000000                  0.428571   \n",
       "1                             0.000000                  0.818182   \n",
       "2                             0.000000                  0.733333   \n",
       "3                             0.040816                  0.673469   \n",
       "4                             0.101266                  1.088608   \n",
       "\n",
       "   non_powerplay_is_wicket_mean  \n",
       "0                      0.071429  \n",
       "1                      0.000000  \n",
       "2                      0.000000  \n",
       "3                      0.081633  \n",
       "4                      0.101266  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batter_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bowler</th>\n",
       "      <th>total_batter_runs_conceded_mean</th>\n",
       "      <th>total_runs_from_relevant_extras_mean</th>\n",
       "      <th>total_total_runs_conceded_mean</th>\n",
       "      <th>total_taken_from_relevant_wickets_mean</th>\n",
       "      <th>powerplay_batter_runs_conceded_mean</th>\n",
       "      <th>powerplay_runs_from_relevant_extras_mean</th>\n",
       "      <th>powerplay_total_runs_conceded_mean</th>\n",
       "      <th>powerplay_taken_from_relevant_wickets_mean</th>\n",
       "      <th>non_powerplay_batter_runs_conceded_mean</th>\n",
       "      <th>non_powerplay_runs_from_relevant_extras_mean</th>\n",
       "      <th>non_powerplay_total_runs_conceded_mean</th>\n",
       "      <th>non_powerplay_taken_from_relevant_wickets_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00029c30</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.090909</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>1.151515</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00321fff</td>\n",
       "      <td>1.067210</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>1.107943</td>\n",
       "      <td>0.052953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.067210</td>\n",
       "      <td>0.036660</td>\n",
       "      <td>1.107943</td>\n",
       "      <td>0.052953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00467a76</td>\n",
       "      <td>1.236742</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>1.348485</td>\n",
       "      <td>0.066288</td>\n",
       "      <td>1.331034</td>\n",
       "      <td>0.048276</td>\n",
       "      <td>1.427586</td>\n",
       "      <td>0.055172</td>\n",
       "      <td>1.201044</td>\n",
       "      <td>0.075718</td>\n",
       "      <td>1.318538</td>\n",
       "      <td>0.070496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005f0561</td>\n",
       "      <td>0.864734</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.757396</td>\n",
       "      <td>0.017751</td>\n",
       "      <td>0.775148</td>\n",
       "      <td>0.041420</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.024490</td>\n",
       "      <td>0.983673</td>\n",
       "      <td>0.069388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007113d7</td>\n",
       "      <td>1.008584</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>1.068670</td>\n",
       "      <td>0.081545</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.008584</td>\n",
       "      <td>0.025751</td>\n",
       "      <td>1.068670</td>\n",
       "      <td>0.081545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bowler  total_batter_runs_conceded_mean  \\\n",
       "0  00029c30                         1.090909   \n",
       "1  00321fff                         1.067210   \n",
       "2  00467a76                         1.236742   \n",
       "3  005f0561                         0.864734   \n",
       "4  007113d7                         1.008584   \n",
       "\n",
       "   total_runs_from_relevant_extras_mean  total_total_runs_conceded_mean  \\\n",
       "0                              0.060606                        1.151515   \n",
       "1                              0.036660                        1.107943   \n",
       "2                              0.068182                        1.348485   \n",
       "3                              0.021739                        0.898551   \n",
       "4                              0.025751                        1.068670   \n",
       "\n",
       "   total_taken_from_relevant_wickets_mean  \\\n",
       "0                                0.045455   \n",
       "1                                0.052953   \n",
       "2                                0.066288   \n",
       "3                                0.057971   \n",
       "4                                0.081545   \n",
       "\n",
       "   powerplay_batter_runs_conceded_mean  \\\n",
       "0                                  NaN   \n",
       "1                                  NaN   \n",
       "2                             1.331034   \n",
       "3                             0.757396   \n",
       "4                                  NaN   \n",
       "\n",
       "   powerplay_runs_from_relevant_extras_mean  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                  0.048276   \n",
       "3                                  0.017751   \n",
       "4                                       NaN   \n",
       "\n",
       "   powerplay_total_runs_conceded_mean  \\\n",
       "0                                 NaN   \n",
       "1                                 NaN   \n",
       "2                            1.427586   \n",
       "3                            0.775148   \n",
       "4                                 NaN   \n",
       "\n",
       "   powerplay_taken_from_relevant_wickets_mean  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                    0.055172   \n",
       "3                                    0.041420   \n",
       "4                                         NaN   \n",
       "\n",
       "   non_powerplay_batter_runs_conceded_mean  \\\n",
       "0                                 1.090909   \n",
       "1                                 1.067210   \n",
       "2                                 1.201044   \n",
       "3                                 0.938776   \n",
       "4                                 1.008584   \n",
       "\n",
       "   non_powerplay_runs_from_relevant_extras_mean  \\\n",
       "0                                      0.060606   \n",
       "1                                      0.036660   \n",
       "2                                      0.075718   \n",
       "3                                      0.024490   \n",
       "4                                      0.025751   \n",
       "\n",
       "   non_powerplay_total_runs_conceded_mean  \\\n",
       "0                                1.151515   \n",
       "1                                1.107943   \n",
       "2                                1.318538   \n",
       "3                                0.983673   \n",
       "4                                1.068670   \n",
       "\n",
       "   non_powerplay_taken_from_relevant_wickets_mean  \n",
       "0                                        0.045455  \n",
       "1                                        0.052953  \n",
       "2                                        0.070496  \n",
       "3                                        0.069388  \n",
       "4                                        0.081545  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowler_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplay_balls = data[data['powerplay'] == True][['batter', 'bowler', 'is_wicket']]\n",
    "powerplay_batter_stats = batter_stats[['batter'] + [col for col in batter_stats.columns if 'powerplay' in col[:9]]]\n",
    "powerplay_bowler_stats = bowler_stats[['bowler'] + [col for col in bowler_stats.columns if 'powerplay' in col[:9]]]\n",
    "\n",
    "non_powerplay_balls = data[data['powerplay'] == False][['batter', 'bowler', 'is_wicket']]\n",
    "non_powerplay_batter_stats = batter_stats[['batter'] + [col for col in batter_stats.columns if 'non_powerplay' in col[:13]]]\n",
    "non_powerplay_bowler_stats = bowler_stats[['bowler'] + [col for col in bowler_stats.columns if 'non_powerplay' in col[:13]]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to time constraints, their performance and ease of use, I will be using a random forest classifierto predict the probability of a wicket occuring in a ball. It's ability to easily return class probabilities rather than just the classes makes it useful here too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_wicket</th>\n",
       "      <th>powerplay_runs_batter_mean</th>\n",
       "      <th>powerplay_high_scoring_hit_mean</th>\n",
       "      <th>powerplay_total_mean</th>\n",
       "      <th>powerplay_is_wicket_mean</th>\n",
       "      <th>powerplay_batter_runs_conceded_mean</th>\n",
       "      <th>powerplay_runs_from_relevant_extras_mean</th>\n",
       "      <th>powerplay_total_runs_conceded_mean</th>\n",
       "      <th>powerplay_taken_from_relevant_wickets_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>1.387970</td>\n",
       "      <td>0.237594</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>1.202899</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>1.269151</td>\n",
       "      <td>0.055901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>1.307902</td>\n",
       "      <td>0.220708</td>\n",
       "      <td>1.376022</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>1.202899</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>1.269151</td>\n",
       "      <td>0.055901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>1.387970</td>\n",
       "      <td>0.237594</td>\n",
       "      <td>1.460150</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>1.202899</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>1.269151</td>\n",
       "      <td>0.055901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>1.182553</td>\n",
       "      <td>0.198708</td>\n",
       "      <td>1.277868</td>\n",
       "      <td>0.048465</td>\n",
       "      <td>1.202899</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>1.269151</td>\n",
       "      <td>0.055901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>1.182553</td>\n",
       "      <td>0.198708</td>\n",
       "      <td>1.277868</td>\n",
       "      <td>0.048465</td>\n",
       "      <td>1.202899</td>\n",
       "      <td>0.045549</td>\n",
       "      <td>1.269151</td>\n",
       "      <td>0.055901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_wicket  powerplay_runs_batter_mean  powerplay_high_scoring_hit_mean  \\\n",
       "0      False                    1.387970                         0.237594   \n",
       "1      False                    1.307902                         0.220708   \n",
       "2       True                    1.387970                         0.237594   \n",
       "3      False                    1.182553                         0.198708   \n",
       "4      False                    1.182553                         0.198708   \n",
       "\n",
       "   powerplay_total_mean  powerplay_is_wicket_mean  \\\n",
       "0              1.460150                  0.042105   \n",
       "1              1.376022                  0.054496   \n",
       "2              1.460150                  0.042105   \n",
       "3              1.277868                  0.048465   \n",
       "4              1.277868                  0.048465   \n",
       "\n",
       "   powerplay_batter_runs_conceded_mean  \\\n",
       "0                             1.202899   \n",
       "1                             1.202899   \n",
       "2                             1.202899   \n",
       "3                             1.202899   \n",
       "4                             1.202899   \n",
       "\n",
       "   powerplay_runs_from_relevant_extras_mean  \\\n",
       "0                                  0.045549   \n",
       "1                                  0.045549   \n",
       "2                                  0.045549   \n",
       "3                                  0.045549   \n",
       "4                                  0.045549   \n",
       "\n",
       "   powerplay_total_runs_conceded_mean  \\\n",
       "0                            1.269151   \n",
       "1                            1.269151   \n",
       "2                            1.269151   \n",
       "3                            1.269151   \n",
       "4                            1.269151   \n",
       "\n",
       "   powerplay_taken_from_relevant_wickets_mean  \n",
       "0                                    0.055901  \n",
       "1                                    0.055901  \n",
       "2                                    0.055901  \n",
       "3                                    0.055901  \n",
       "4                                    0.055901  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerplay_balls_stats = powerplay_balls.merge(powerplay_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "powerplay_balls_stats = powerplay_balls_stats.merge(powerplay_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])\n",
    "\n",
    "non_powerplay_balls_stats = non_powerplay_balls.merge(non_powerplay_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "non_powerplay_balls_stats = non_powerplay_balls_stats.merge(non_powerplay_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])\n",
    "powerplay_balls_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_powerplay = powerplay_balls_stats.drop(columns=['is_wicket'])\n",
    "y_powerplay = powerplay_balls_stats['is_wicket']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay, y_powerplay, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Use it\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m powerplay_wicket_model \u001b[38;5;241m=\u001b[39m \u001b[43mdo_random_forest_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[89], line 14\u001b[0m, in \u001b[0;36mdo_random_forest_classifier\u001b[0;34m(X_train, y_train, cv, random_state, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier(\n\u001b[1;32m      9\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mrandom_state,\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Cross validation with probability predictions and verbose output\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroc_auc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mf1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Add verbose output to see training progress\u001b[39;49;00m\n\u001b[1;32m     27\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    481\u001b[0m ]\n\u001b[1;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/ensemble/_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m    201\u001b[0m         X,\n\u001b[1;32m    202\u001b[0m         y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[1;32m    206\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/coding-task-BR_zkfTV-py3.12/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def do_random_forest_classifier(X_train, y_train, cv=5, random_state=42, **kwargs):\n",
    "    \"\"\"\n",
    "    Train Random Forest Classifier and get probability predictions\n",
    "    \"\"\"\n",
    "    # Initialize model\n",
    "    model = RandomForestClassifier(\n",
    "        random_state=random_state,\n",
    "        **kwargs\n",
    "    )\n",
    "    \n",
    "    # Cross validation with probability predictions and verbose output\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring={\n",
    "            'auc': 'roc_auc',\n",
    "            'precision': 'precision', \n",
    "            'recall': 'recall',\n",
    "            'f1': 'f1'\n",
    "        },\n",
    "        return_train_score=True,\n",
    "        verbose=1 # Add verbose output to see training progress\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Example of getting probabilities\n",
    "    # proba = model.predict_proba(X)  # Returns [[prob_class0, prob_class1], ...]\n",
    "    # wicket_prob = proba[:, 1]  # Just the probability of wicket (class 1)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"Model Performance:\")\n",
    "    print(f\"Train AUC: {cv_results['train_auc'].mean():.3f} ± {cv_results['train_auc'].std():.3f}\")\n",
    "    print(f\"CV AUC: {cv_results['test_auc'].mean():.3f} ± {cv_results['test_auc'].std():.3f}\")\n",
    "\n",
    "    print(f\"Precision: {cv_results['test_precision'].mean():.3f} ± {cv_results['test_precision'].std():.3f}\")\n",
    "    print(f\"Recall: {cv_results['test_recall'].mean():.3f} ± {cv_results['test_recall'].std():.3f}\")\n",
    "    print(f\"F1 Score: {cv_results['test_f1'].mean():.3f} ± {cv_results['test_f1'].std():.3f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Use it\n",
    "powerplay_wicket_model = do_random_forest_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.90514423, 0.09485577],\n",
       "       ...,\n",
       "       [0.8163913 , 0.1836087 ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerplay_results = powerplay_wicket_model.predict_proba(X_test)\n",
    "powerplay_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of balls where wicket chance is 0: 0.568\n",
      "Max wicket chance: 0.950\n",
      "Mean wicket chance: 0.040\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion of balls where wicket chance is 0: {len(powerplay_results[powerplay_results[:, 1] == 0]) / len(powerplay_results):.3f}\")\n",
    "print(f\"Max wicket chance: {powerplay_results[:, 1].max():.3f}\")\n",
    "print(f\"Mean wicket chance: {powerplay_results[:, 1].mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a face value these results look awful, and were we trying to use this to classify whether or not a wicket occurs they would be.\n",
    "\n",
    "However, we are trying to predict the probability of a wicket occuring in a ball. Binary classification models return the class with the highest proability - which in our case will pretty much always be no wicket...\n",
    "\n",
    "Therefore, I do not think the low auc/f1 values are a problem.\n",
    "\n",
    "I am however more concerned about the high number of balls with a wicket chance of 0. Since technically, there is always a small chance of a wicket occuring, I am going to add a small 'fudge factor' to the predictions to ensure that this always exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean actual wicket chance: 0.044\n",
      "Mean predicted wicket chance: 0.040\n",
      "STD of actual wicket chance: 0.205\n",
      "STD of predicted wicket chance: 0.094\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean actual wicket chance: {powerplay_balls_stats['is_wicket'].mean():.3f}\")\n",
    "print(f\"Mean predicted wicket chance: {powerplay_results[:, 1].mean():.3f}\")\n",
    "\n",
    "print(f\"STD of actual wicket chance: {powerplay_balls_stats['is_wicket'].std():.3f}\")\n",
    "print(f\"STD of predicted wicket chance: {powerplay_results[:, 1].std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean wicket chance outputted by the model is 0.04, very similar to the actual wicket chance of 0.039, suggesting that the model is actually fairly representative of the actual wicket chance.\n",
    "\n",
    "Therefore I probably want the fudge factor to be small but non-zero, keeping the mean predicted wicket chance close to the actual wicket chance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New mean predicted wicket chance: 0.050\n"
     ]
    }
   ],
   "source": [
    "def predict_wicket_probability(model, X, fudge_factor=0.01):\n",
    "    wicket_prob = model.predict_proba(X)[:, 1]\n",
    "    wicket_prop = wicket_prob * (1 - fudge_factor) + fudge_factor\n",
    "    return wicket_prop\n",
    "\n",
    "powerplay_results = predict_wicket_probability(powerplay_wicket_model, X_test, 0.01)\n",
    "print(f\"New mean predicted wicket chance: {powerplay_results.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a fudge factor of 1% seems to be alright. While it is arbitrarily chosen, it does keep the mean chance similar to the actual chance while ensuring that there is somewhat of a chance of a wicket occuring at all times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non powerplay wickets\n",
    "\n",
    "Again, I am going to repeat the exact same process for the non powerplay wickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_non_powerplay = non_powerplay_balls_stats.drop(columns=['is_wicket'])\n",
    "y_non_powerplay = non_powerplay_balls_stats['is_wicket']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_non_powerplay, y_non_powerplay, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Train AUC: 0.950 ± 0.000\n",
      "CV AUC: 0.571 ± 0.003\n",
      "Precision: 0.053 ± 0.004\n",
      "Recall: 0.012 ± 0.001\n",
      "F1 Score: 0.020 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "non_powerplay_wicket_model = do_random_forest_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of balls where wicket chance is 0: 0.480\n",
      "Max wicket chance: 0.968\n",
      "Mean wicket chance: 0.057\n"
     ]
    }
   ],
   "source": [
    "non_powerplay_results = predict_wicket_probability(non_powerplay_wicket_model, X_test, 0)\n",
    "print(f\"Proportion of balls where wicket chance is 0: {len(non_powerplay_results[non_powerplay_results == 0]) / len(non_powerplay_results):.3f}\")\n",
    "print(f\"Max wicket chance: {non_powerplay_results.max():.3f}\")\n",
    "print(f\"Mean wicket chance: {non_powerplay_results.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean actual wicket chance: 0.061\n",
      "Mean predicted wicket chance: 0.057\n",
      "STD of actual wicket chance: 0.238\n",
      "STD of predicted wicket chance: 0.113\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean actual wicket chance: {non_powerplay_balls_stats['is_wicket'].mean():.3f}\")\n",
    "print(f\"Mean predicted wicket chance: {non_powerplay_results.mean():.3f}\")\n",
    "\n",
    "print(f\"STD of actual wicket chance: {non_powerplay_balls_stats['is_wicket'].std():.3f}\")\n",
    "print(f\"STD of predicted wicket chance: {non_powerplay_results.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we see that the model is fairly representative of the actual wicket chance, good signs all around.\n",
    "\n",
    "I think I will stick with the same fudge factor of 1% for the non powerplay wickets to keep things consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New mean predicted wicket chance: 0.066\n"
     ]
    }
   ],
   "source": [
    "non_powerplay_results = predict_wicket_probability(non_powerplay_wicket_model, X_test, 0.01)\n",
    "print(f\"New mean predicted wicket chance: {non_powerplay_results.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this remains within ±1% of the actual wicket chance, I'm happy with this for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Predicting the number of extras resulting from a ball\n",
    "\n",
    "I think I am going to break this down into three models:\n",
    "1. A model predicting the probability of an extra occuring in a ball.\n",
    "2. A model predicting the type of extra | an extra has occured.\n",
    "3. A model predicting the number of extras occuring in a ball | The type of extra\n",
    "\n",
    "This should help solve the problem of the high number of extra balls where the number of extras is 0, which would likely skew the predictions if I were to use just a single model.\n",
    "\n",
    "Again, I am going to use a random forest classifier for this task.\n",
    "\n",
    "## 2.a) Predicting the probability of an extra occuring in a ball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Powerplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplay_extra_balls = data[data['powerplay'] == True][['batter', 'bowler', 'extras']]\n",
    "powerplay_extra_batter_stats = batter_stats[['batter'] + [col for col in batter_stats.columns if 'powerplay' in col[:9]]]\n",
    "powerplay_extra_bowler_stats = bowler_stats[['bowler'] + [col for col in bowler_stats.columns if 'powerplay' in col[:9]]]\n",
    "\n",
    "non_powerplay_extra_balls = data[data['powerplay'] == False][['batter', 'bowler', 'extras']]\n",
    "non_powerplay_extra_batter_stats = batter_stats[['batter'] + [col for col in batter_stats.columns if 'non_powerplay' in col[:13]]]\n",
    "non_powerplay_extra_bowler_stats = bowler_stats[['bowler'] + [col for col in bowler_stats.columns if 'non_powerplay' in col[:13]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.09018491859723067)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerplay_extra_balls['extras'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 269524 entries, 0 to 857110\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype \n",
      "---  ------     --------------   ----- \n",
      " 0   batter     269524 non-null  object\n",
      " 1   bowler     269524 non-null  object\n",
      " 2   extras     269524 non-null  int64 \n",
      " 3   is_extras  269524 non-null  bool  \n",
      "dtypes: bool(1), int64(1), object(2)\n",
      "memory usage: 8.5+ MB\n"
     ]
    }
   ],
   "source": [
    "powerplay_extra_balls['is_extras'] = powerplay_extra_balls['extras'] > 0\n",
    "powerplay_extra_balls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplay_extra_balls = powerplay_extra_balls.merge(powerplay_extra_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "powerplay_extra_balls = powerplay_extra_balls.merge(powerplay_extra_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_powerplay = powerplay_extra_balls.drop(columns=['extras', 'is_extras'])\n",
    "y_powerplay = powerplay_extra_balls['is_extras']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay, y_powerplay, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Train AUC: 0.918 ± 0.000\n",
      "CV AUC: 0.580 ± 0.004\n",
      "Precision: 0.138 ± 0.005\n",
      "Recall: 0.032 ± 0.003\n",
      "F1 Score: 0.052 ± 0.004\n"
     ]
    }
   ],
   "source": [
    "extras_model = do_random_forest_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of balls where extra chance is 0: 0.412\n",
      "Max extra chance: 0.973\n",
      "Mean extra chance: 0.073\n"
     ]
    }
   ],
   "source": [
    "powerplay_results = predict_wicket_probability(extras_model, X_test, 0)\n",
    "print(f\"Proportion of balls where extra chance is 0: {len(powerplay_results[powerplay_results == 0]) / len(powerplay_results):.3f}\")\n",
    "print(f\"Max extra chance: {powerplay_results.max():.3f}\")\n",
    "print(f\"Mean extra chance: {powerplay_results.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean actual extra chance: 0.090\n",
      "Mean predicted extra chance: 0.073\n",
      "STD of actual extra chance: 0.392\n",
      "STD of predicted extra chance: 0.122\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean actual extra chance: {powerplay_extra_balls['extras'].mean():.3f}\")\n",
    "print(f\"Mean predicted extra chance: {powerplay_results.mean():.3f}\")\n",
    "\n",
    "print(f\"STD of actual extra chance: {powerplay_extra_balls['extras'].std():.3f}\")\n",
    "print(f\"STD of predicted extra chance: {powerplay_results.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting to see that the predictions are less accurate here than for the wickets. Its still within ±2% of the actual mean chance, but not as close as I would like.\n",
    "\n",
    "That being said, again adding a fudge factor of 1% seems like it would be alright, and in fact would bring the mean predicted extra chance closer to the actual extra chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New mean predicted extra chance: 0.082\n"
     ]
    }
   ],
   "source": [
    "powerplay_results = predict_wicket_probability(extras_model, X_test, 0.01)\n",
    "print(f\"New mean predicted extra chance: {powerplay_results.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non powerplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Train AUC: 0.932 ± 0.000\n",
      "CV AUC: 0.577 ± 0.004\n",
      "Precision: 0.120 ± 0.009\n",
      "Recall: 0.027 ± 0.002\n",
      "F1 Score: 0.044 ± 0.003\n",
      "Proportion of balls where extra chance is 0: 0.453\n",
      "Max extra chance: 0.970\n",
      "Mean extra chance: 0.063\n",
      "\n",
      "Mean actual extra chance: 0.075\n",
      "Mean predicted extra chance: 0.063\n",
      "STD of actual extra chance: 0.347\n",
      "STD of predicted extra chance: 0.115\n"
     ]
    }
   ],
   "source": [
    "non_powerplay_extra_balls['is_extras'] = non_powerplay_extra_balls['extras'] > 0\n",
    "non_powerplay_extra_balls = non_powerplay_extra_balls.merge(non_powerplay_extra_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "non_powerplay_extra_balls = non_powerplay_extra_balls.merge(non_powerplay_extra_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])\n",
    "X_non_powerplay = non_powerplay_extra_balls.drop(columns=['extras', 'is_extras'])\n",
    "y_non_powerplay = non_powerplay_extra_balls['is_extras']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_non_powerplay, y_non_powerplay, test_size=0.2, random_state=42)\n",
    "non_powerplay_extras_model = do_random_forest_classifier(X_train, y_train)\n",
    "non_powerplay_results = predict_wicket_probability(non_powerplay_extras_model, X_test, 0)\n",
    "print(f\"Proportion of balls where extra chance is 0: {len(non_powerplay_results[non_powerplay_results == 0]) / len(non_powerplay_results):.3f}\")\n",
    "print(f\"Max extra chance: {non_powerplay_results.max():.3f}\")\n",
    "print(f\"Mean extra chance: {non_powerplay_results.mean():.3f}\")\n",
    "print(f\"\\nMean actual extra chance: {non_powerplay_extra_balls['extras'].mean():.3f}\")\n",
    "print(f\"Mean predicted extra chance: {non_powerplay_results.mean():.3f}\")\n",
    "\n",
    "print(f\"STD of actual extra chance: {non_powerplay_extra_balls['extras'].std():.3f}\")\n",
    "print(f\"STD of predicted extra chance: {non_powerplay_results.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a fudge factor of 1% seems appropriate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New mean predicted extra chance: 0.072\n"
     ]
    }
   ],
   "source": [
    "non_powerplay_results = predict_wicket_probability(non_powerplay_extras_model, X_test, 0.01)\n",
    "print(f\"New mean predicted extra chance: {non_powerplay_results.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.b) Predicting the type of extra | an extra has occured\n",
    "\n",
    "My hope here is that using the batter and bowler stats we can predict the type of extra that occurs.\n",
    "\n",
    "Depending on the success of this, I may instead just try to predict the number of runs|extra occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "balls_with_extras = data[data['extras'] > 0][['batter', 'bowler', 'extras_details', 'extras', 'powerplay']]\n",
    "balls_with_extras['extras_details'] = balls_with_extras['extras_details'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extras_details\n",
       "{'wides': 1}                    32496\n",
       "{'legbyes': 1}                   9435\n",
       "{'noballs': 1}                   4455\n",
       "{'byes': 1}                      2385\n",
       "{'wides': 2}                     2120\n",
       "{'wides': 5}                      989\n",
       "{'legbyes': 2}                    754\n",
       "{'byes': 4}                       704\n",
       "{'legbyes': 4}                    630\n",
       "{'wides': 3}                      536\n",
       "{'byes': 2}                       433\n",
       "{'byes': 1, 'noballs': 1}         104\n",
       "{'wides': 4}                       57\n",
       "{'legbyes': 3}                     56\n",
       "{'byes': 4, 'noballs': 1}          43\n",
       "{'byes': 3}                        38\n",
       "{'legbyes': 1, 'noballs': 1}       24\n",
       "{'byes': 2, 'noballs': 1}          22\n",
       "{'legbyes': 5}                     13\n",
       "{'penalty': 5}                     12\n",
       "{'noballs': 5}                     10\n",
       "{'noballs': 2}                     10\n",
       "{'legbyes': 4, 'noballs': 1}        4\n",
       "{'legbyes': 2, 'noballs': 1}        2\n",
       "{'byes': 5}                         2\n",
       "{'legbyes': 1, 'penalty': 5}        1\n",
       "{'noballs': 3}                      1\n",
       "{'noballs': 1, 'penalty': 5}        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balls_with_extras['extras_details'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extras_details\n",
       "[wides]               36198\n",
       "[legbyes]             10888\n",
       "[noballs]              4476\n",
       "[byes]                 3562\n",
       "[byes, noballs]         159\n",
       "[legbyes, noballs]       29\n",
       "[penalty]                12\n",
       "[noballs, byes]          10\n",
       "[legbyes, penalty]        1\n",
       "[noballs, legbyes]        1\n",
       "[noballs, penalty]        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balls_with_extras['extras_details'].apply(lambda x: list(x.keys())).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55337, 5)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balls_with_extras.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extras_details\n",
       "{'noballs': 1}    4455\n",
       "{'noballs': 5}      10\n",
       "{'noballs': 2}      10\n",
       "{'noballs': 3}       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noballs_balls = balls_with_extras[balls_with_extras['extras_details'].apply(lambda x: list(x.keys()) == ['noballs'])]\n",
    "noballs_balls['extras_details'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a couple if issues here:\n",
    "1. If we are trying to predict the number of extra runs | extra occurs, the results are massively skewed towards 1.\n",
    "2. If we are trying to predict the number of extra runs | extra type the results will still heavily be skewed towards 1 for the extras from which there can be a variable number of runs.\n",
    "\n",
    "I think this is a lose-lose situation, but at least predicting the probability of an extra type should help in the case of extras where there is a fixed number of runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extras_type\n",
       "wides      36198\n",
       "legbyes    10919\n",
       "noballs     4676\n",
       "byes        3731\n",
       "penalty       14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balls_with_extras['extras_type'] = balls_with_extras['extras_details'].apply(lambda x: list(x.keys()))\n",
    "# Explode the extras_type column to create separate rows for each extra type\n",
    "exploded_extras = balls_with_extras.explode('extras_type')\n",
    "exploded_extras['extras_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5 types of extras. Since we can have multiple extras in a ball, I am going to use 5 different models to predict the probability of each type occuring.\n",
    "\n",
    "For the sake of length and readability, I am going to limit my explanations/analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortuntely due to the way the data is structured I can't use one_hot_encoding with the exploded rows\n",
    "# without duplicating rows, so I will just create the columns manually.\n",
    "balls_with_extras['wides'] = balls_with_extras['extras_details'].apply(lambda x: 'wides' in list(x.keys()))\n",
    "balls_with_extras['byes'] = balls_with_extras['extras_details'].apply(lambda x: 'byes' in list(x.keys()))\n",
    "balls_with_extras['legbyes'] = balls_with_extras['extras_details'].apply(lambda x: 'legbyes' in list(x.keys()))\n",
    "balls_with_extras['noballs'] = balls_with_extras['extras_details'].apply(lambda x: 'noballs' in list(x.keys()))\n",
    "balls_with_extras['penalty'] = balls_with_extras['extras_details'].apply(lambda x: 'penalty' in list(x.keys()))\n",
    "extras_dropped = balls_with_extras.drop(columns=['extras_details', 'extras_type', 'extras'])\n",
    "\n",
    "powerplay_extra_balls = extras_dropped[extras_dropped['powerplay']].drop(columns=['powerplay'])\n",
    "powerplay_extra_balls = powerplay_extra_balls.merge(powerplay_extra_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "powerplay_extra_balls = powerplay_extra_balls.merge(powerplay_extra_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])\n",
    "\n",
    "non_powerplay_extra_balls = extras_dropped[extras_dropped['powerplay'] == False].drop(columns=['powerplay'])\n",
    "non_powerplay_extra_balls = non_powerplay_extra_balls.merge(non_powerplay_extra_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "non_powerplay_extra_balls = non_powerplay_extra_balls.merge(non_powerplay_extra_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Powerplay wides model:\n",
      "Model Performance:\n",
      "Train AUC: 0.986 ± 0.000\n",
      "CV AUC: 0.616 ± 0.007\n",
      "Precision: 0.727 ± 0.004\n",
      "Recall: 0.849 ± 0.007\n",
      "F1 Score: 0.783 ± 0.004\n",
      "Powerplay byes model:\n",
      "Model Performance:\n",
      "Train AUC: 0.997 ± 0.000\n",
      "CV AUC: 0.587 ± 0.012\n",
      "Precision: 0.116 ± 0.034\n",
      "Recall: 0.031 ± 0.010\n",
      "F1 Score: 0.049 ± 0.015\n",
      "Powerplay legbyes model:\n",
      "Model Performance:\n",
      "Train AUC: 0.992 ± 0.000\n",
      "CV AUC: 0.661 ± 0.004\n",
      "Precision: 0.347 ± 0.009\n",
      "Recall: 0.158 ± 0.010\n",
      "F1 Score: 0.217 ± 0.010\n",
      "Powerplay noballs model:\n",
      "Model Performance:\n",
      "Train AUC: 0.994 ± 0.000\n",
      "CV AUC: 0.608 ± 0.017\n",
      "Precision: 0.254 ± 0.064\n",
      "Recall: 0.088 ± 0.029\n",
      "F1 Score: 0.130 ± 0.040\n"
     ]
    }
   ],
   "source": [
    "# Wides:\n",
    "# For the sake of time I am going to limit the max depth of the trees to 30, otherwise I will be sitting here for hours...\n",
    "X_powerplay_wides = powerplay_extra_balls.drop(columns=['wides', 'byes', 'legbyes', 'noballs', 'penalty'])\n",
    "y_powerplay_wides = powerplay_extra_balls['wides']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay_wides, y_powerplay_wides, test_size=0.2, random_state=42)\n",
    "print(f\"Powerplay wides model:\")\n",
    "powerplay_wides_model = do_random_forest_classifier(X_train, y_train, max_depth=30)\n",
    "test_wides = predict_wicket_probability(powerplay_wides_model, X_test, 0)\n",
    "\n",
    "# Byes:\n",
    "X_powerplay_byes = powerplay_extra_balls.drop(columns=['wides', 'byes', 'legbyes', 'noballs', 'penalty'])\n",
    "y_powerplay_byes = powerplay_extra_balls['byes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay_byes, y_powerplay_byes, test_size=0.2, random_state=42)\n",
    "print(f\"Powerplay byes model:\")\n",
    "powerplay_byes_model = do_random_forest_classifier(X_train, y_train, max_depth=30)\n",
    "test_byes = predict_wicket_probability(powerplay_byes_model, X_test, 0)\n",
    "# Legbyes:\n",
    "X_powerplay_legbyes = powerplay_extra_balls.drop(columns=['wides', 'byes', 'legbyes', 'noballs', 'penalty'])\n",
    "y_powerplay_legbyes = powerplay_extra_balls['legbyes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay_legbyes, y_powerplay_legbyes, test_size=0.2, random_state=42)\n",
    "print(f\"Powerplay legbyes model:\")\n",
    "powerplay_legbyes_model = do_random_forest_classifier(X_train, y_train, max_depth=30)\n",
    "test_legbyes = predict_wicket_probability(powerplay_legbyes_model, X_test, 0)\n",
    "\n",
    "# Noballs:\n",
    "X_powerplay_noballs = powerplay_extra_balls.drop(columns=['wides', 'byes', 'legbyes', 'noballs', 'penalty'])\n",
    "y_powerplay_noballs = powerplay_extra_balls['noballs']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay_noballs, y_powerplay_noballs, test_size=0.2, random_state=42)\n",
    "print(f\"Powerplay noballs model:\")\n",
    "powerplay_noballs_model = do_random_forest_classifier(X_train, y_train, max_depth=30)\n",
    "test_noballs = predict_wicket_probability(powerplay_noballs_model, X_test, 0)\n",
    "# Penalties:\n",
    "# There are no penalites in the powerplay data, and only 14 in the non powerplay data.\n",
    "# I am hence going to just model this as a random chance, especially considering that the batter/bolwer skill\n",
    "# in theory should have no impact on the probability of a penalty occuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean actual wides chance: 0.694\n",
      "Mean predicted wides chance: 0.696\n",
      "Proportion of balls where wides chance is 0: 0.000\n",
      "\n",
      "Mean actual byes chance: 0.044\n",
      "Mean predicted byes chance: 0.048\n",
      "Proportion of balls where byes chance is 0: 0.139\n",
      "\n",
      "Mean actual legbyes chance: 0.191\n",
      "Mean predicted legbyes chance: 0.195\n",
      "Proportion of balls where legbyes chance is 0: 0.061\n",
      "\n",
      "Mean actual noballs chance: 0.074\n",
      "Mean predicted noballs chance: 0.080\n",
      "Proportion of balls where noballs chance is 0: 0.068\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean actual wides chance: {powerplay_extra_balls['wides'].mean():.3f}\")\n",
    "print(f\"Mean predicted wides chance: {test_wides.mean():.3f}\")\n",
    "print(f\"Proportion of balls where wides chance is 0: {len(test_wides[test_wides == 0]) / len(test_wides):.3f}\\n\")\n",
    "\n",
    "print(f\"Mean actual byes chance: {powerplay_extra_balls['byes'].mean():.3f}\")\n",
    "print(f\"Mean predicted byes chance: {test_byes.mean():.3f}\")\n",
    "print(f\"Proportion of balls where byes chance is 0: {len(test_byes[test_byes == 0]) / len(test_byes):.3f}\\n\")\n",
    "print(f\"Mean actual legbyes chance: {powerplay_extra_balls['legbyes'].mean():.3f}\")\n",
    "print(f\"Mean predicted legbyes chance: {test_legbyes.mean():.3f}\")\n",
    "print(f\"Proportion of balls where legbyes chance is 0: {len(test_legbyes[test_legbyes == 0]) / len(test_legbyes):.3f}\\n\")\n",
    "\n",
    "print(f\"Mean actual noballs chance: {powerplay_extra_balls['noballs'].mean():.3f}\")\n",
    "print(f\"Mean predicted noballs chance: {test_noballs.mean():.3f}\")\n",
    "print(f\"Proportion of balls where noballs chance is 0: {len(test_noballs[test_noballs == 0]) / len(test_noballs):.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good to see that the chances fairly match up again. Due to the very low number of zeroes, I do not think that adding a fudge factor will be necessary here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non powerplay wides model:\n",
      "Model Performance:\n",
      "Train AUC: 0.988 ± 0.000\n",
      "CV AUC: 0.610 ± 0.004\n",
      "Precision: 0.672 ± 0.002\n",
      "Recall: 0.786 ± 0.006\n",
      "F1 Score: 0.724 ± 0.003\n",
      "Non powerplay byes model:\n",
      "Model Performance:\n",
      "Train AUC: 0.997 ± 0.000\n",
      "CV AUC: 0.598 ± 0.006\n",
      "Precision: 0.131 ± 0.025\n",
      "Recall: 0.027 ± 0.006\n",
      "F1 Score: 0.045 ± 0.010\n",
      "Non powerplay legbyes model:\n",
      "Model Performance:\n",
      "Train AUC: 0.994 ± 0.000\n",
      "CV AUC: 0.650 ± 0.005\n",
      "Precision: 0.353 ± 0.021\n",
      "Recall: 0.138 ± 0.005\n",
      "F1 Score: 0.198 ± 0.008\n",
      "Non powerplay noballs model:\n",
      "Model Performance:\n",
      "Train AUC: 0.994 ± 0.000\n",
      "CV AUC: 0.605 ± 0.008\n",
      "Precision: 0.275 ± 0.018\n",
      "Recall: 0.094 ± 0.004\n",
      "F1 Score: 0.140 ± 0.006\n"
     ]
    }
   ],
   "source": [
    "# Wides:\n",
    "# For the sake of time I am going to limit the max depth of the trees to 30, otherwise I will be sitting here for hours...\n",
    "X_non_powerplay_wides = non_powerplay_extra_balls.drop(columns=['wides', 'byes', 'legbyes', 'noballs', 'penalty'])\n",
    "y_non_powerplay_wides = non_powerplay_extra_balls['wides']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_non_powerplay_wides, y_non_powerplay_wides, test_size=0.2, random_state=42)\n",
    "print(f\"Non powerplay wides model:\")\n",
    "non_powerplay_wides_model = do_random_forest_classifier(X_train, y_train, max_depth=30)\n",
    "test_wides = predict_wicket_probability(non_powerplay_wides_model, X_test, 0)\n",
    "\n",
    "# Byes:\n",
    "X_non_powerplay_byes = non_powerplay_extra_balls.drop(columns=['wides', 'byes', 'legbyes', 'noballs', 'penalty'])\n",
    "y_non_powerplay_byes = non_powerplay_extra_balls['byes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_non_powerplay_byes, y_non_powerplay_byes, test_size=0.2, random_state=42)\n",
    "print(f\"Non powerplay byes model:\")\n",
    "non_powerplay_byes_model = do_random_forest_classifier(X_train, y_train, max_depth=30)\n",
    "test_byes = predict_wicket_probability(non_powerplay_byes_model, X_test, 0)\n",
    "\n",
    "# Legbyes:\n",
    "X_non_powerplay_legbyes = non_powerplay_extra_balls.drop(columns=['wides', 'byes', 'legbyes', 'noballs', 'penalty'])\n",
    "y_non_powerplay_legbyes = non_powerplay_extra_balls['legbyes']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_non_powerplay_legbyes, y_non_powerplay_legbyes, test_size=0.2, random_state=42)\n",
    "print(f\"Non powerplay legbyes model:\")\n",
    "non_powerplay_legbyes_model = do_random_forest_classifier(X_train, y_train, max_depth=30)\n",
    "test_legbyes = predict_wicket_probability(non_powerplay_legbyes_model, X_test, 0)\n",
    "\n",
    "# Noballs:\n",
    "X_non_powerplay_noballs = non_powerplay_extra_balls.drop(columns=['wides', 'byes', 'legbyes', 'noballs', 'penalty'])\n",
    "y_non_powerplay_noballs = non_powerplay_extra_balls['noballs']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_non_powerplay_noballs, y_non_powerplay_noballs, test_size=0.2, random_state=42)\n",
    "print(f\"Non powerplay noballs model:\")\n",
    "non_powerplay_noballs_model = do_random_forest_classifier(X_train, y_train, max_depth=30)\n",
    "test_noballs = predict_wicket_probability(non_powerplay_noballs_model, X_test, 0)\n",
    "\n",
    "# Penalty:\n",
    "# See above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean actual wides chance: 0.633\n",
      "Mean predicted wides chance: 0.631\n",
      "Proportion of balls where wides chance is 0: 0.000\n",
      "\n",
      "Mean actual byes chance: 0.080\n",
      "Mean predicted byes chance: 0.085\n",
      "Proportion of balls where byes chance is 0: 0.068\n",
      "\n",
      "Mean actual legbyes chance: 0.201\n",
      "Mean predicted legbyes chance: 0.207\n",
      "Proportion of balls where legbyes chance is 0: 0.055\n",
      "\n",
      "Mean actual noballs chance: 0.090\n",
      "Mean predicted noballs chance: 0.097\n",
      "Proportion of balls where noballs chance is 0: 0.023\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean actual wides chance: {non_powerplay_extra_balls['wides'].mean():.3f}\")\n",
    "print(f\"Mean predicted wides chance: {test_wides.mean():.3f}\")\n",
    "print(f\"Proportion of balls where wides chance is 0: {len(test_wides[test_wides == 0]) / len(test_wides):.3f}\\n\")\n",
    "\n",
    "print(f\"Mean actual byes chance: {non_powerplay_extra_balls['byes'].mean():.3f}\")\n",
    "print(f\"Mean predicted byes chance: {test_byes.mean():.3f}\")\n",
    "print(f\"Proportion of balls where byes chance is 0: {len(test_byes[test_byes == 0]) / len(test_byes):.3f}\\n\")\n",
    "print(f\"Mean actual legbyes chance: {non_powerplay_extra_balls['legbyes'].mean():.3f}\")\n",
    "print(f\"Mean predicted legbyes chance: {test_legbyes.mean():.3f}\")\n",
    "print(f\"Proportion of balls where legbyes chance is 0: {len(test_legbyes[test_legbyes == 0]) / len(test_legbyes):.3f}\\n\")\n",
    "\n",
    "print(f\"Mean actual noballs chance: {non_powerplay_extra_balls['noballs'].mean():.3f}\")\n",
    "print(f\"Mean predicted noballs chance: {test_noballs.mean():.3f}\")\n",
    "print(f\"Proportion of balls where noballs chance is 0: {len(test_noballs[test_noballs == 0]) / len(test_noballs):.3f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this seems to match up remarkably well. Also again, due to the very low number of zeroes, I do not think that adding a fudge factor will be needed here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.c) Predicting the number of extras occuring in a ball | The type of extra\n",
    "\n",
    "Again, I will be limiting my comments/explanations due to the length of this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need a regression model rather than a classifier here.\n",
    "def do_random_forest_regressor(X_train, y_train, cv=5, random_state=42, **kwargs):\n",
    "    model = RandomForestRegressor(random_state=random_state, **kwargs)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_results = cross_validate(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=cv,\n",
    "        scoring={\n",
    "            'r2': 'r2',\n",
    "            'rmse': 'neg_root_mean_squared_error',\n",
    "            'mape': 'neg_mean_absolute_percentage_error'\n",
    "        },\n",
    "        return_train_score=True\n",
    "    )\n",
    "    \n",
    "    # Fit final model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Analyze CV results\n",
    "    analysis = {\n",
    "        'r2': {\n",
    "            'train_avg': cv_results['train_r2'].mean(),\n",
    "            'train_std': cv_results['train_r2'].std(),\n",
    "            'cv_avg': cv_results['test_r2'].mean(),\n",
    "            'cv_std': cv_results['test_r2'].std(),\n",
    "            'gap': cv_results['train_r2'].mean() - cv_results['test_r2'].mean(),\n",
    "            'consistency': 'Stable' if cv_results['test_r2'].std() < 0.05 else 'Unstable'\n",
    "        },\n",
    "        'rmse': {\n",
    "            'train_avg': -cv_results['train_rmse'].mean(),\n",
    "            'train_std': cv_results['train_rmse'].std(),\n",
    "            'cv_avg': -cv_results['test_rmse'].mean(),\n",
    "            'cv_std': cv_results['test_rmse'].std(),\n",
    "            'gap': -cv_results['test_rmse'].mean() - (-cv_results['train_rmse'].mean())\n",
    "        },\n",
    "        'mape': {\n",
    "            'train_avg': -cv_results['train_mape'].mean(),\n",
    "            'train_std': cv_results['train_mape'].std(),\n",
    "            'cv_avg': -cv_results['test_mape'].mean(),\n",
    "            'cv_std': cv_results['test_mape'].std(),\n",
    "            'gap': -cv_results['test_mape'].mean() - (-cv_results['train_mape'].mean())\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"Cross-Validation Analysis:\")\n",
    "    print(\"\\nR² Scores:\")\n",
    "    print(f\"Training Average: {analysis['r2']['train_avg']:.3f} ± {analysis['r2']['train_std']:.3f}\")\n",
    "    print(f\"CV Average: {analysis['r2']['cv_avg']:.3f} ± {analysis['r2']['cv_std']:.3f}\")\n",
    "    print(f\"Gap (Train-CV): {analysis['r2']['gap']:.3f}\")\n",
    "    print(f\"CV Consistency: {analysis['r2']['consistency']}\")\n",
    "    \n",
    "    print(\"\\nRMSE Scores:\")\n",
    "    print(f\"Training Average: {analysis['rmse']['train_avg']:.3f} ± {analysis['rmse']['train_std']:.3f}\")\n",
    "    print(f\"CV Average: {analysis['rmse']['cv_avg']:.3f} ± {analysis['rmse']['cv_std']:.3f}\")\n",
    "    print(f\"Gap (CV-Train): {analysis['rmse']['gap']:.3f}\")\n",
    "    \n",
    "    print(\"\\nMAPE Scores:\")\n",
    "    print(f\"Training Average: {analysis['mape']['train_avg']:.3f} ± {analysis['mape']['train_std']:.3f}\")\n",
    "    print(f\"CV Average: {analysis['mape']['cv_avg']:.3f} ± {analysis['mape']['cv_std']:.3f}\")\n",
    "    print(f\"Gap (CV-Train): {analysis['mape']['gap']:.3f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Importance': model.feature_importances_\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Most Important Features:\")\n",
    "    print(feature_importance.head(10))\n",
    "    \n",
    "    return model, analysis, feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batter</th>\n",
       "      <th>bowler</th>\n",
       "      <th>extras_details</th>\n",
       "      <th>extras</th>\n",
       "      <th>powerplay</th>\n",
       "      <th>extras_type</th>\n",
       "      <th>wides</th>\n",
       "      <th>byes</th>\n",
       "      <th>legbyes</th>\n",
       "      <th>noballs</th>\n",
       "      <th>penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>09a9d073</td>\n",
       "      <td>3a60e0b5</td>\n",
       "      <td>{'wides': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>[wides]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>73c18486</td>\n",
       "      <td>e62dd25d</td>\n",
       "      <td>{'legbyes': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>[legbyes]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>09a9d073</td>\n",
       "      <td>6a26221c</td>\n",
       "      <td>{'wides': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[wides]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>650d5e49</td>\n",
       "      <td>8361e524</td>\n",
       "      <td>{'legbyes': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[legbyes]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>650d5e49</td>\n",
       "      <td>81c36ee9</td>\n",
       "      <td>{'wides': 1}</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[wides]</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batter    bowler  extras_details  extras  powerplay extras_type  wides  \\\n",
       "17  09a9d073  3a60e0b5    {'wides': 1}       1       True     [wides]   True   \n",
       "33  73c18486  e62dd25d  {'legbyes': 1}       1       True   [legbyes]  False   \n",
       "51  09a9d073  6a26221c    {'wides': 1}       1      False     [wides]   True   \n",
       "76  650d5e49  8361e524  {'legbyes': 1}       1      False   [legbyes]  False   \n",
       "99  650d5e49  81c36ee9    {'wides': 1}       1      False     [wides]   True   \n",
       "\n",
       "     byes  legbyes  noballs  penalty  \n",
       "17  False    False    False    False  \n",
       "33  False     True    False    False  \n",
       "51  False    False    False    False  \n",
       "76  False     True    False    False  \n",
       "99  False    False    False    False  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balls_with_extras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batter</th>\n",
       "      <th>bowler</th>\n",
       "      <th>powerplay</th>\n",
       "      <th>extras_type</th>\n",
       "      <th>extras_from_relevant_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>09a9d073</td>\n",
       "      <td>3a60e0b5</td>\n",
       "      <td>True</td>\n",
       "      <td>wides</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>73c18486</td>\n",
       "      <td>e62dd25d</td>\n",
       "      <td>True</td>\n",
       "      <td>legbyes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>09a9d073</td>\n",
       "      <td>6a26221c</td>\n",
       "      <td>False</td>\n",
       "      <td>wides</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>650d5e49</td>\n",
       "      <td>8361e524</td>\n",
       "      <td>False</td>\n",
       "      <td>legbyes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>650d5e49</td>\n",
       "      <td>81c36ee9</td>\n",
       "      <td>False</td>\n",
       "      <td>wides</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      batter    bowler  powerplay extras_type  extras_from_relevant_type\n",
       "17  09a9d073  3a60e0b5       True       wides                          1\n",
       "33  73c18486  e62dd25d       True     legbyes                          1\n",
       "51  09a9d073  6a26221c      False       wides                          1\n",
       "76  650d5e49  8361e524      False     legbyes                          1\n",
       "99  650d5e49  81c36ee9      False       wides                          1"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploded_extras = balls_with_extras.explode('extras_type')\n",
    "exploded_extras['extras_from_relevant_type'] = exploded_extras.apply(lambda row: row['extras_details'].get(row['extras_type'], 0), axis=1)\n",
    "exploded_extras = exploded_extras.drop(columns=['extras_details', 'wides', 'byes', 'legbyes', 'noballs', 'penalty', 'extras'])\n",
    "exploded_extras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplay_extra_balls = exploded_extras[exploded_extras['powerplay']].drop(columns=['powerplay'])\n",
    "powerplay_extra_balls = powerplay_extra_balls.merge(powerplay_extra_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "powerplay_extra_balls = powerplay_extra_balls.merge(powerplay_extra_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])\n",
    "non_powerplay_extra_balls = exploded_extras[exploded_extras['powerplay'] == False].drop(columns=['powerplay'])\n",
    "non_powerplay_extra_balls = non_powerplay_extra_balls.merge(non_powerplay_extra_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "non_powerplay_extra_balls = non_powerplay_extra_balls.merge(non_powerplay_extra_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])\n",
    "\n",
    "# Wides:\n",
    "print(f\"\\nPowerplay wides model:\")\n",
    "X_powerplay_wides = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'wides'].drop(columns=['extras_type', 'extras_from_relevant_type'])\n",
    "y_powerplay_wides = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'wides']['extras_from_relevant_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay_wides, y_powerplay_wides, test_size=0.2, random_state=42)\n",
    "powerplay_wides_model, _, _ = do_random_forest_regressor(X_train, y_train, max_depth=30)\n",
    "\n",
    "# Byes:\n",
    "print(f\"\\nPowerplay byes model:\")\n",
    "X_powerplay_byes = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'byes'].drop(columns=['extras_type', 'extras_from_relevant_type'])\n",
    "y_powerplay_byes = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'byes']['extras_from_relevant_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay_byes, y_powerplay_byes, test_size=0.2, random_state=42)\n",
    "powerplay_byes_model, _, _ = do_random_forest_regressor(X_train, y_train, max_depth=30)\n",
    "\n",
    "# Legbyes:\n",
    "print(f\"\\nPowerplay legbyes model:\")\n",
    "X_powerplay_legbyes = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'legbyes'].drop(columns=['extras_type', 'extras_from_relevant_type'])\n",
    "y_powerplay_legbyes = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'legbyes']['extras_from_relevant_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_powerplay_legbyes, y_powerplay_legbyes, test_size=0.2, random_state=42)\n",
    "powerplay_legbyes_model, _, _ = do_random_forest_regressor(X_train, y_train, max_depth=30)\n",
    "\n",
    "# Noballs and penalties result in a fixed number of extras, so these do not need modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results here show that the model is not very good at predicting the number of extras occuring in a ball.\n",
    "\n",
    "This is likely due to a combination of factors:\n",
    "1. The number of extras is almsot always 1, so the model struggles to predict different values.\n",
    "2. The amount of data is fairly limited, so the model is unable to learn well.\n",
    "\n",
    "I do not think that we will be able to predict this with any model so trying would be a waste of time, however there are a few other options.\n",
    "\n",
    "1. Just set the number of extras to 1 for all types - as this is almost always the case it should not lead to significant issues.\n",
    "2. Use a probability distribution to predict the number of extras occuring depending on the type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of wides leading to 1 extra: 0.900\n",
      "Proportion of byes leading to 1 extra: 0.597\n",
      "Proportion of legbyes leading to 1 extra: 0.846\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion of wides leading to 1 extra: {powerplay_extra_balls[(powerplay_extra_balls['extras_type'] == 'wides') & (powerplay_extra_balls['extras_from_relevant_type'] == 1)].shape[0] / powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'wides'].shape[0]:.3f}\")\n",
    "print(f\"Proportion of byes leading to 1 extra: {powerplay_extra_balls[(powerplay_extra_balls['extras_type'] == 'byes') & (powerplay_extra_balls['extras_from_relevant_type'] == 1)].shape[0] / powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'byes'].shape[0]:.3f}\")\n",
    "print(f\"Proportion of legbyes leading to 1 extra: {powerplay_extra_balls[(powerplay_extra_balls['extras_type'] == 'legbyes') & (powerplay_extra_balls['extras_from_relevant_type'] == 1)].shape[0] / powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'legbyes'].shape[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the proportions for wides and legbyes scoring 1 extra are quite high, there is still a non-negligable chance of more extras occuring. Byes in particular see a significant chance of >1 extra being scored.\n",
    "\n",
    "I think therefore the second option will be better.\n",
    "Since the number of runs that are scored when such extras occur can easily be down to luck rather than skill, fitting a distribution to the data should not be too bad a representation. I think we should still filter by powerplay/non-powerplay here, due to the fact that the less fielders on the field will likely increase the number of extras.\n",
    "\n",
    "For simplicity, I will just use an empirical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_empirical_distribution(data):\n",
    "    \"\"\"\n",
    "    Create probability distribution directly from data\n",
    "    \n",
    "    Args:\n",
    "        data: Series of values\n",
    "    \n",
    "    Returns:\n",
    "        values: possible values\n",
    "        probabilities: probability of each value\n",
    "    \"\"\"\n",
    "    # Get value counts and convert to probabilities\n",
    "    value_counts = data.value_counts()\n",
    "    total = len(data)\n",
    "    probabilities = value_counts / total\n",
    "    \n",
    "    # Sort by value for clarity\n",
    "    probabilities = probabilities.sort_index()\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "powerplay_wides = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'wides']['extras_from_relevant_type']\n",
    "powerplay_byes = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'byes']['extras_from_relevant_type']\n",
    "powerplay_legbyes = powerplay_extra_balls[powerplay_extra_balls['extras_type'] == 'legbyes']['extras_from_relevant_type']\n",
    "powerplay_wides_probs = get_empirical_distribution(powerplay_wides)\n",
    "powerplay_byes_probs = get_empirical_distribution(powerplay_byes)\n",
    "powerplay_legbyes_probs = get_empirical_distribution(powerplay_legbyes)\n",
    "\n",
    "non_powerplay_wides = non_powerplay_extra_balls[non_powerplay_extra_balls['extras_type'] == 'wides']['extras_from_relevant_type']\n",
    "non_powerplay_byes = non_powerplay_extra_balls[non_powerplay_extra_balls['extras_type'] == 'byes']['extras_from_relevant_type']\n",
    "non_powerplay_legbyes = non_powerplay_extra_balls[non_powerplay_extra_balls['extras_type'] == 'legbyes']['extras_from_relevant_type']\n",
    "non_powerplay_wides_probs = get_empirical_distribution(non_powerplay_wides)\n",
    "non_powerplay_byes_probs = get_empirical_distribution(non_powerplay_byes)\n",
    "non_powerplay_legbyes_probs = get_empirical_distribution(non_powerplay_legbyes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Prediciting the number of runs scored from a ball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 857199 entries, 0 to 857198\n",
      "Data columns (total 29 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   game_id               857199 non-null  object \n",
      " 1   date                  857199 non-null  object \n",
      " 2   venue                 857199 non-null  object \n",
      " 3   location              816895 non-null  object \n",
      " 4   gender                857199 non-null  object \n",
      " 5   match_type            857199 non-null  object \n",
      " 6   innings               857199 non-null  int64  \n",
      " 7   batting_team          857199 non-null  object \n",
      " 8   bowling_team          857199 non-null  object \n",
      " 9   batting_team_players  857199 non-null  object \n",
      " 10  bowling_team_players  857199 non-null  object \n",
      " 11  over                  857199 non-null  int64  \n",
      " 12  ball_in_over          857199 non-null  int64  \n",
      " 13  batter                857199 non-null  object \n",
      " 14  bowler                857199 non-null  object \n",
      " 15  non_striker           857199 non-null  object \n",
      " 16  runs_batter           857199 non-null  int64  \n",
      " 17  extras                857199 non-null  int64  \n",
      " 18  total                 857199 non-null  int64  \n",
      " 19  is_wicket             857199 non-null  bool   \n",
      " 20  wicket_type           47416 non-null   object \n",
      " 21  fielder               29853 non-null   object \n",
      " 22  player_out            47416 non-null   object \n",
      " 23  target_runs           392608 non-null  float64\n",
      " 24  target_overs          392608 non-null  float64\n",
      " 25  current_runs          857199 non-null  int64  \n",
      " 26  current_wickets       857199 non-null  int64  \n",
      " 27  powerplay             857199 non-null  bool   \n",
      " 28  extras_details        55337 non-null   object \n",
      "dtypes: bool(2), float64(2), int64(8), object(17)\n",
      "memory usage: 178.2+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freehit\n",
       "False    852523\n",
       "True       4676\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle both dict and float (NaN) cases\n",
    "data['extras_parsed'] = data['extras_details'].apply(lambda x: ast.literal_eval(x) if not pd.isna(x) else {})\n",
    "data['freehit'] = data['extras_parsed'].apply(lambda x: 'noballs' in list(x.keys()))\n",
    "data['freehit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batter</th>\n",
       "      <th>bowler</th>\n",
       "      <th>powerplay</th>\n",
       "      <th>freehit</th>\n",
       "      <th>runs_batter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7fca84b7</td>\n",
       "      <td>3a60e0b5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>73c18486</td>\n",
       "      <td>3a60e0b5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7fca84b7</td>\n",
       "      <td>3a60e0b5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>09a9d073</td>\n",
       "      <td>3a60e0b5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09a9d073</td>\n",
       "      <td>3a60e0b5</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     batter    bowler  powerplay  freehit  runs_batter\n",
       "0  7fca84b7  3a60e0b5       True    False            1\n",
       "1  73c18486  3a60e0b5       True    False            1\n",
       "2  7fca84b7  3a60e0b5       True    False            0\n",
       "3  09a9d073  3a60e0b5       True    False            0\n",
       "4  09a9d073  3a60e0b5       True    False            4"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_data = data[['batter', 'bowler', 'powerplay', 'freehit', 'runs_batter']]\n",
    "runs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "runs_batter\n",
       "0    406520\n",
       "1    285508\n",
       "4     77460\n",
       "2     58822\n",
       "6     24971\n",
       "3      3796\n",
       "5       120\n",
       "7         2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_data['runs_batter'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data here is extremely unbalances, making the job of a predictive model difficult.\n",
    "\n",
    "I think in this situation using an empirical distribution will be the best option. However, I am going to segment the data by powerplay/non-powerplay and then further my considering the skill of the bowler compared to the batter.\n",
    "\n",
    "I will compare their average runs conceded/made per ball to determine skill levels, and segment the data into 3 groups based on this:\n",
    "1. Bowler is better than batter\n",
    "2. Bowler is worse than batter\n",
    "3. Bowler is about the same as batter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "powerplay_runs_data = runs_data[runs_data['powerplay']].drop(columns=['powerplay'])\n",
    "powerplay_runs_data = powerplay_runs_data.merge(powerplay_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "powerplay_runs_data = powerplay_runs_data.merge(powerplay_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])\n",
    "\n",
    "non_powerplay_runs_data = runs_data[~runs_data['powerplay']].drop(columns=['powerplay'])\n",
    "non_powerplay_runs_data = non_powerplay_runs_data.merge(non_powerplay_batter_stats, on='batter', how='left').drop(columns=['batter'])\n",
    "non_powerplay_runs_data = non_powerplay_runs_data.merge(non_powerplay_bowler_stats, on='bowler', how='left').drop(columns=['bowler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding-task-BR_zkfTV-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
